{"cells":[{"cell_type":"code","source":["import pandas as pd\nimport glob\nimport yaml\nimport os\nfrom datetime import datetime"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"a87b928b-ae86-40e9-8f07-92d7ce2a4e6c","inputWidgets":{},"title":"Load relevant packages"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%run ../0_Config.ipynb"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e77b5a16-5ee2-4361-bb0b-eec7f97c1904","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Choose the algorithms to see if any exceptions occured\nalgorithms = ['ElasticNet','ExponentialSmoothingHolt','ExponentialSmoothingHoltWinters','Lasso_cvglmnet','Prophet',\\\n              'SARIMAX','SimpleExponentialSmoothing','XGBoost','DeepAR','DeepState','LSTM'] \noutput_directory = os.path.join(app_config['output_dir_path'],\"Modeling_Results\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"aefd246f-5116-44c8-9b6e-e0b1509d8ed9","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["backtesting_results_fin = pd.DataFrame()\n\nfor algo in algorithms:\n    algo_path = os.path.join(output_directory,algo)\n    if glob.glob(algo_path):\n        # Reading the latest file based on timestamp\n        all_files = [file for file in os.listdir(algo_path)]\n        backtesting_files = [file for file in all_files if \"Backtesting_results_window_level (\" in file]\n        if(len(backtesting_files)>0):\n            backtesting_files = [file.replace(\".csv\",\"\") for file in backtesting_files]\n            print(algo)\n            version_dates = [datetime.strptime(x.split('(')[1].replace(')',''), '%Y-%m-%d-%H-%M-%S') for x in backtesting_files]\n            max_date = max(version_dates)\n            max_date = max_date.strftime('%Y-%m-%d-%H-%M-%S')\n            req_file_name = [x for x in backtesting_files if max_date in x]\n            backtesting_results_file_path = os.path.join(algo_path,req_file_name[0] + '.csv')\n            backtesting_results = pd.read_csv(backtesting_results_file_path)\n            backtesting_results = backtesting_results[backtesting_results[\"status\"] != \"success\"]\n            if(algo in ['DeepAR','DeepState']):\n                backtesting_results = backtesting_results[list(set(app_config['modeling_granularity']+\\\n                                                                          app_config[\"Algorithms\"][\"DeepAR\"][\"global_model_gran\"]))+[\"status\"]]\n            else:\n                backtesting_results = backtesting_results[app_config['modeling_granularity']+[\"status\"]]\n            backtesting_results['algorithm'] = algo\n            backtesting_results_fin = pd.concat([backtesting_results_fin,backtesting_results], ignore_index = True)\n        else:\n            print(\"No Backtesting_results_window_level for \"+algo)\n    else:\n        print(algo_path+\" >>> does not exists\")\n            \n# Dropping duplicates if any\nbacktesting_results_fin = backtesting_results_fin.drop_duplicates()\n\n# Exporting the final file\nexport_path = os.path.join(output_directory, 'Exceptions')\nif not os.path.exists(export_path):\n    os.makedirs(export_path)\n    \nif(backtesting_results_fin.shape[0]):    \n    backtesting_results_fin.to_csv(export_path+\"/Backtesting_exceptions_window_level (\"+datetime.today().strftime('%Y-%m-%d-%H-%M-%S')+\").csv\", index = False)\n\nbacktesting_results_fin"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"30bbe6cd-a056-47eb-982b-22edf81bfe63","inputWidgets":{},"title":"Exceptions while implementing backtesting"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">ElasticNet\nExponentialSmoothingHolt\nExponentialSmoothingHoltWinters\nNo Backtesting_results_window_level for Lasso_cvglmnet\nProphet\nSARIMAX\nSimpleExponentialSmoothing\n/dbfs/mnt/solutionsadls_data/modeling_results_python/Modeling_Results/XGBoost &gt;&gt;&gt; does not exists\nDeepAR\nLSTM\nOut[11]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">ElasticNet\nExponentialSmoothingHolt\nExponentialSmoothingHoltWinters\nNo Backtesting_results_window_level for Lasso_cvglmnet\nProphet\nSARIMAX\nSimpleExponentialSmoothing\n/dbfs/mnt/solutionsadls_data/modeling_results_python/Modeling_Results/XGBoost &gt;&gt;&gt; does not exists\nDeepAR\nLSTM\nOut[11]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Div_No</th>\n      <th>Store_No</th>\n      <th>Base_UPC</th>\n      <th>status</th>\n      <th>algorithm</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Div_No</th>\n      <th>Store_No</th>\n      <th>Base_UPC</th>\n      <th>status</th>\n      <th>algorithm</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["best_hyperparam_results_fin = pd.DataFrame()\n\nfor algo in algorithms:\n    algo_path = os.path.join(output_directory,algo)\n    \n    if glob.glob(algo_path):\n        # Reading the latest file based on timestamp\n        all_files = [file for file in os.listdir(algo_path)]\n        best_hyperparameters_files = [file for file in all_files if \"Best_hyperparameters (\" in file]\n        if(len(best_hyperparameters_files)>0):\n            best_hyperparameters_files = [file.replace(\".csv\",\"\") for file in best_hyperparameters_files]\n            print(algo)\n            version_dates = [datetime.strptime(x.split('(')[1].replace(')',''), '%Y-%m-%d-%H-%M-%S') for x in best_hyperparameters_files]\n            max_date = max(version_dates)\n            max_date = max_date.strftime('%Y-%m-%d-%H-%M-%S')\n            req_file_name = [x for x in best_hyperparameters_files if max_date in x]\n            best_hyperparameters_file_path = os.path.join(algo_path,req_file_name[0] + \".csv\")\n            best_hyperparam_results = pd.read_csv(best_hyperparameters_file_path)\n            best_hyperparam_results = best_hyperparam_results[best_hyperparam_results['status'] != 'success']\n            if(algo in ['DeepAR','DeepState']):\n                best_hyperparam_results = best_hyperparam_results[app_config[\"Algorithms\"][\"DeepAR\"][\"global_model_gran\"]+[\"status\"]]\n            else:\n                best_hyperparam_results = best_hyperparam_results[app_config['modeling_granularity']+[\"status\"]]\n            best_hyperparam_results['algorithm'] = algo\n            best_hyperparam_results_fin = pd.concat([best_hyperparam_results_fin,best_hyperparam_results], ignore_index = True)\n        else:\n            print(\"No Best_hyperparameters for \"+algo)\n    else:\n        print(algo_path+\" >>> does not exists\")\n        \n# Dropping duplicates if any\nbest_hyperparam_results_fin = best_hyperparam_results_fin.drop_duplicates()\n\n# Exporting the final file\nexport_path = os.path.join(output_directory, 'Exceptions')\nif not os.path.exists(export_path):\n    os.makedirs(export_path)\n    \nif(best_hyperparam_results_fin.shape[0]):\n    best_hyperparam_results_fin.to_csv(export_path+\"/Best_hyperparameters_exceptions (\"+datetime.today().strftime('%Y-%m-%d-%H-%M-%S')+\").csv\", index = False)\n\nbest_hyperparam_results_fin"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"47f130f4-f34f-4601-a595-d5c77e47fe22","inputWidgets":{},"title":"Exceptions while choosing best hyperparameters"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">ElasticNet\nExponentialSmoothingHolt\nExponentialSmoothingHoltWinters\nNo Best_hyperparameters for Lasso_cvglmnet\nProphet\nSARIMAX\nSimpleExponentialSmoothing\n/dbfs/mnt/solutionsadls_data/modeling_results_python/Modeling_Results/XGBoost &gt;&gt;&gt; does not exists\nDeepAR\nLSTM\nOut[12]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">ElasticNet\nExponentialSmoothingHolt\nExponentialSmoothingHoltWinters\nNo Best_hyperparameters for Lasso_cvglmnet\nProphet\nSARIMAX\nSimpleExponentialSmoothing\n/dbfs/mnt/solutionsadls_data/modeling_results_python/Modeling_Results/XGBoost &gt;&gt;&gt; does not exists\nDeepAR\nLSTM\nOut[12]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Div_No</th>\n      <th>Store_No</th>\n      <th>Base_UPC</th>\n      <th>status</th>\n      <th>algorithm</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Div_No</th>\n      <th>Store_No</th>\n      <th>Base_UPC</th>\n      <th>status</th>\n      <th>algorithm</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["Out_of_sample_results_fin = pd.DataFrame()\n\nfor algo in algorithms:\n    algo_path = os.path.join(output_directory,algo)\n    \n    if glob.glob(algo_path):\n        # Reading the latest file based on timestamp\n        all_files = [file for file in os.listdir(algo_path)]\n        Out_of_sample_files = [file for file in all_files if \"Out_of_sample_evaluation_results (\" in file]\n        if(len(Out_of_sample_files)>0):\n            Out_of_sample_files = [file.replace(\".csv\",\"\") for file in Out_of_sample_files]\n            print(algo)\n            version_dates = [datetime.strptime(x.split('(')[1].replace(')',''), '%Y-%m-%d-%H-%M-%S') for x in Out_of_sample_files]\n            max_date = max(version_dates)\n            max_date = max_date.strftime('%Y-%m-%d-%H-%M-%S')\n            req_file_name = [x for x in Out_of_sample_files if max_date in x]\n            Out_of_sample_file_path = os.path.join(algo_path,req_file_name[0] + \".csv\")\n            Out_of_sample_results = pd.read_csv(Out_of_sample_file_path)\n            Out_of_sample_results = Out_of_sample_results[Out_of_sample_results['status'] != 'success']\n            Out_of_sample_results = Out_of_sample_results[app_config['modeling_granularity']+[\"status\"]]\n            Out_of_sample_results['algorithm'] = algo\n            Out_of_sample_results_fin = pd.concat([Out_of_sample_results_fin,Out_of_sample_results], ignore_index = True)\n        else:\n            print(\"No Out_of_sample_evaluation_results for \"+algo)\n    else:\n        print(algo_path+\" >>> does not exists\")\n        \n# Dropping duplicates if any\nOut_of_sample_results_fin = Out_of_sample_results_fin.drop_duplicates()\n\n# Exporting the final file\nexport_path = os.path.join(output_directory, 'Exceptions')\nif not os.path.exists(export_path):\n    os.makedirs(export_path)\n    \nif(Out_of_sample_results_fin.shape[0]):\n    Out_of_sample_results_fin.to_csv(export_path+\"/Out_of_sample_evaluation_exceptions (\"+datetime.today().strftime('%Y-%m-%d-%H-%M-%S')+\").csv\", index = False)\n\nOut_of_sample_results_fin"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"f0c65760-d69f-4244-b956-64f7344d0c86","inputWidgets":{},"title":"Exceptions while building final model"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">ElasticNet\nExponentialSmoothingHolt\nExponentialSmoothingHoltWinters\nLasso_cvglmnet\nProphet\nSARIMAX\nSimpleExponentialSmoothing\n/dbfs/mnt/solutionsadls_data/modeling_results_python/Modeling_Results/XGBoost &gt;&gt;&gt; does not exists\nDeepAR\nLSTM\nOut[13]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">ElasticNet\nExponentialSmoothingHolt\nExponentialSmoothingHoltWinters\nLasso_cvglmnet\nProphet\nSARIMAX\nSimpleExponentialSmoothing\n/dbfs/mnt/solutionsadls_data/modeling_results_python/Modeling_Results/XGBoost &gt;&gt;&gt; does not exists\nDeepAR\nLSTM\nOut[13]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Div_No</th>\n      <th>Store_No</th>\n      <th>Base_UPC</th>\n      <th>status</th>\n      <th>algorithm</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Div_No</th>\n      <th>Store_No</th>\n      <th>Base_UPC</th>\n      <th>status</th>\n      <th>algorithm</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["future_forecast_results_fin = pd.DataFrame()\n\nfor algo in algorithms:\n    algo_path = os.path.join(output_directory,algo)\n    \n    if glob.glob(algo_path):\n        # Reading the latest file based on timestamp\n        all_files = [file for file in os.listdir(algo_path)]\n        future_forecast_files = [file for file in all_files if \"Future_forecast_results (\" in file]\n        if(len(future_forecast_files)>0):\n            future_forecast_files = [file.replace(\".csv\",\"\") for file in future_forecast_files]\n            print(algo)\n            version_dates = [datetime.strptime(x.split('(')[1].replace(')',''), '%Y-%m-%d-%H-%M-%S') for x in future_forecast_files]\n            max_date = max(version_dates)\n            max_date = max_date.strftime('%Y-%m-%d-%H-%M-%S')\n            req_file_name = [x for x in future_forecast_files if max_date in x]\n            future_forecast_file_path = os.path.join(algo_path,req_file_name[0] + \".csv\")\n            future_forecast_results = pd.read_csv(future_forecast_file_path)\n            future_forecast_results = future_forecast_results[future_forecast_results['status'] != 'success']\n            future_forecast_results = future_forecast_results[app_config['modeling_granularity']+[\"status\"]]\n            future_forecast_results['algorithm'] = algo\n            future_forecast_results_fin = pd.concat([future_forecast_results_fin,future_forecast_results], ignore_index = True)\n        else:\n            print(\"No Future_forecast_results for \"+algo)\n    else:\n        print(algo_path+\" >>> does not exists\")\n        \n# Dropping duplicates if any\nfuture_forecast_results_fin = future_forecast_results_fin.drop_duplicates()\n\n# Exporting the final file\nexport_path = os.path.join(output_directory, 'Exceptions')\nif not os.path.exists(export_path):\n    os.makedirs(export_path)\n    \nif(future_forecast_results_fin.shape[0]):\n    future_forecast_results_fin.to_csv(export_path+\"/Future_forecast_exceptions (\"+datetime.today().strftime('%Y-%m-%d-%H-%M-%S')+\").csv\", index = False)\n\nfuture_forecast_results_fin"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"d20af579-530f-461c-9c70-b0ca7422421b","inputWidgets":{},"title":"Exceptions while forecasting future periods"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">No Future_forecast_results for ElasticNet\nNo Future_forecast_results for ExponentialSmoothingHolt\nNo Future_forecast_results for ExponentialSmoothingHoltWinters\nNo Future_forecast_results for Lasso_cvglmnet\nNo Future_forecast_results for Prophet\nNo Future_forecast_results for SARIMAX\nNo Future_forecast_results for SimpleExponentialSmoothing\n/dbfs/mnt/solutionsadls_data/modeling_results_python/Modeling_Results/XGBoost &gt;&gt;&gt; does not exists\nNo Future_forecast_results for DeepAR\nNo Future_forecast_results for LSTM\nOut[14]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">No Future_forecast_results for ElasticNet\nNo Future_forecast_results for ExponentialSmoothingHolt\nNo Future_forecast_results for ExponentialSmoothingHoltWinters\nNo Future_forecast_results for Lasso_cvglmnet\nNo Future_forecast_results for Prophet\nNo Future_forecast_results for SARIMAX\nNo Future_forecast_results for SimpleExponentialSmoothing\n/dbfs/mnt/solutionsadls_data/modeling_results_python/Modeling_Results/XGBoost &gt;&gt;&gt; does not exists\nNo Future_forecast_results for DeepAR\nNo Future_forecast_results for LSTM\nOut[14]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["coeff_results = pd.DataFrame()\n\noutput_directory = os.path.join(app_config['output_dir_path'],\"Data_Processing\")\nalgo_path = os.path.join(app_config['output_dir_path'],\"Data_Processing\",'modeling_level_trend')\nif glob.glob(algo_path):\n    # Reading the latest file based on timestamp\n    all_files = [file for file in os.listdir(algo_path)]\n    files = [file for file in all_files if \"granular_level_trend_results (\" in file]\n    if(len(files)>0):\n        files = [file.replace(\".csv\",\"\") for file in files]\n        print('Granular level trend results')\n        version_dates = [datetime.strptime(x.split('(')[1].replace(')',''), '%Y-%m-%d-%H-%M-%S') for x in files]\n        max_date = max(version_dates)\n        max_date = max_date.strftime('%Y-%m-%d-%H-%M-%S')\n        req_file_name = [x for x in files if max_date in x]\n        file_path = os.path.join(algo_path,req_file_name[0] + \".csv\")\n        results = pd.read_csv(file_path)\n        results = results[results['status'] != 'success']\n        results = results[app_config['modeling_granularity']+[\"status\"]]\n        coeff_results = pd.concat([coeff_results,results], ignore_index = True)\n    else:\n        print(\"No Granular level trend results\")\nelse:\n        print(algo_path+\" >>> does not exists\")\n        \n# Dropping duplicates if any\ncoeff_results = coeff_results.drop_duplicates()\n\n# Exporting the final file\nexport_path = os.path.join(output_directory, 'Exceptions')\nif not os.path.exists(export_path):\n    os.makedirs(export_path)\n    \nif(coeff_results.shape[0]):\n    coeff_results.to_csv(export_path+\"/granular_level_trend_exceptions (\"+datetime.today().strftime('%Y-%m-%d-%H-%M-%S')+\").csv\", index = False)\n\ncoeff_results  "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"346e989b-c6b5-4cea-9d39-bcda1ffee99b","inputWidgets":{},"title":"Exceptions while running \"Granular Prophet Trend creation\""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Granular level trend results\nOut[15]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Granular level trend results\nOut[15]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Div_No</th>\n      <th>Store_No</th>\n      <th>Base_UPC</th>\n      <th>status</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Div_No</th>\n      <th>Store_No</th>\n      <th>Base_UPC</th>\n      <th>status</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["coeff_results = pd.DataFrame()\n\nalgo_path = os.path.join(app_config['output_dir_path'],\"Data_Processing\",'higher_level_trend_si')\nif glob.glob(algo_path):\n    # Reading the latest file based on timestamp\n    all_files = [file for file in os.listdir(algo_path)]\n    files = [file for file in all_files if \"higher_level_trend_si_results (\" in file]\n    if(len(files)>0):\n        files = [file.replace(\".csv\",\"\") for file in files]\n        print('Higher level trend and si results')\n        version_dates = [datetime.strptime(x.split('(')[1].replace(')',''), '%Y-%m-%d-%H-%M-%S') for x in files]\n        max_date = max(version_dates)\n        max_date = max_date.strftime('%Y-%m-%d-%H-%M-%S')\n        req_file_name = [x for x in files if max_date in x]\n        file_path = os.path.join(algo_path,req_file_name[0] + \".csv\")\n        results = pd.read_csv(file_path)\n        results = results[results['status'] != 'success']\n        results = results[app_config[\"data_processing\"]['feature_engineering']['prophet_based'][\"higher_level_si_trend_creation\"][\"granularity\"]+[\"status\"]]\n        coeff_results = pd.concat([coeff_results,results], ignore_index = True)\n    else:\n        print(\"No higher level trend and si results\")\nelse:\n        print(algo_path+\" >>> does not exists\")\n        \n# Dropping duplicates if any\ncoeff_results = coeff_results.drop_duplicates()\n\n# Exporting the final file\nexport_path = os.path.join(output_directory, 'Exceptions')\nif not os.path.exists(export_path):\n    os.makedirs(export_path)\n    \nif(coeff_results.shape[0]):\n    coeff_results.to_csv(export_path+\"/higher_level_trend_si_exceptions (\"+datetime.today().strftime('%Y-%m-%d-%H-%M-%S')+\").csv\", index = False)\n\ncoeff_results   "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"fb2af8e7-1fb5-4ee9-b852-37d972b3d44a","inputWidgets":{},"title":"Exceptions while running \"Prophet Trend & SI creation\""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Higher level trend and si results\nOut[16]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Higher level trend and si results\nOut[16]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Div_No</th>\n      <th>status</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Div_No</th>\n      <th>status</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["coeff_results = pd.DataFrame()\n\nalgo_path = os.path.join(app_config['output_dir_path'],\"Data_Processing\",'Seasonality_Index')\nif glob.glob(algo_path):\n    # Reading the latest file based on timestamp\n    all_files = [file for file in os.listdir(algo_path)]\n    files = [file for file in all_files if \"SI_results (\" in file]\n    if(len(files)>0):\n        files = [file.replace(\".csv\",\"\") for file in files]\n        print('si results')\n        version_dates = [datetime.strptime(x.split('(')[1].replace(')',''), '%Y-%m-%d-%H-%M-%S') for x in files]\n        max_date = max(version_dates)\n        max_date = max_date.strftime('%Y-%m-%d-%H-%M-%S')\n        req_file_name = [x for x in files if max_date in x]\n        file_path = os.path.join(algo_path,req_file_name[0] + \".csv\")\n        results = pd.read_csv(file_path)\n        results = results[results['status'] != 'success']\n        results = results[app_config[\"data_processing\"]['feature_engineering']['prophet_based'][\"higher_level_si_trend_creation\"][\"granularity\"]+[\"status\"]]\n        coeff_results = pd.concat([coeff_results,results], ignore_index = True)\n    else:\n        print(\"No si results\")\nelse:\n        print(algo_path+\" >>> does not exists\")\n        \n# Dropping duplicates if any\ncoeff_results = coeff_results.drop_duplicates()\n\n# Exporting the final file\nexport_path = os.path.join(output_directory, 'Exceptions')\nif not os.path.exists(export_path):\n    os.makedirs(export_path)\n    \nif(coeff_results.shape[0]):\n    coeff_results.to_csv(export_path+\"/calculated_si_exceptions (\"+datetime.today().strftime('%Y-%m-%d-%H-%M-%S')+\").csv\", index = False)\n\ncoeff_results   "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"640f43ab-2bb3-419a-a14f-4697d70ea3b4","inputWidgets":{},"title":"Exceptions while running \"Calculated SI creation\""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">si results\nOut[17]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">si results\nOut[17]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Div_No</th>\n      <th>status</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Div_No</th>\n      <th>status</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["coeff_results = pd.DataFrame()\n\noutput_directory = os.path.join(app_config['output_dir_path'],\"Feature_Selection\")\nalgo_path = os.path.join(app_config['output_dir_path'],\"Feature_Selection\",'Lasso')\nif glob.glob(algo_path):\n    # Reading the latest file based on timestamp\n    all_files = [file for file in os.listdir(algo_path)]\n    files = [file for file in all_files if \"lasso_feature_selection_results (\" in file]\n    if(len(files)>0):\n        files = [file.replace(\".csv\",\"\") for file in files]\n        print('lasso feature selection results')\n        version_dates = [datetime.strptime(x.split('(')[1].replace(')',''), '%Y-%m-%d-%H-%M-%S') for x in files]\n        max_date = max(version_dates)\n        max_date = max_date.strftime('%Y-%m-%d-%H-%M-%S')\n        req_file_name = [x for x in files if max_date in x]\n        file_path = os.path.join(algo_path,req_file_name[0] + \".csv\")\n        results = pd.read_csv(file_path)\n        results = results[results['status'] != 'success']\n        results = results[app_config[\"modeling_granularity\"]+[\"status\"]]\n        coeff_results = pd.concat([coeff_results,results], ignore_index = True)\n    else:\n        print(\"No lasso feature selection results\")\nelse:\n        print(algo_path+\" >>> does not exists\")\n        \n# Dropping duplicates if any\ncoeff_results = coeff_results.drop_duplicates()\n\n# Exporting the final file\nexport_path = os.path.join(output_directory, 'Exceptions')\nif not os.path.exists(export_path):\n    os.makedirs(export_path)\n    \nif(coeff_results.shape[0]):\n    coeff_results.to_csv(export_path+\"/lasso_feature_selection_exceptions (\"+datetime.today().strftime('%Y-%m-%d-%H-%M-%S')+\").csv\", index = False)\n\ncoeff_results       "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"49860b58-6a71-4179-8745-c7ae71cdc911","inputWidgets":{},"title":"Exceptions while running feature selection \"Lasso using cvglment\""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">lasso feature selection results\nOut[19]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">lasso feature selection results\nOut[19]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Div_No</th>\n      <th>status</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Div_No</th>\n      <th>status</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"5.1 - Exceptions Check","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":98246570295847}},"nbformat":4,"nbformat_minor":0}