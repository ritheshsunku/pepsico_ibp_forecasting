{"cells":[{"cell_type":"markdown","source":["## Timeseries Modeling - Prophet\n### Objective:\nThe objective of the notebook is to -\n* Backtest on all hyperparameters of Prophet provided in the config\n* Find the best set of hyperparameters using the metric provided in the config"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3114b9fc-7828-4869-a545-0cdbb50658a4","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["import yaml\nimport inspect\nimport glob\nimport numpy as np\nimport pandas as pd\nfrom prophet import Prophet\nfrom prophet.make_holidays import make_holidays_df\nfrom distutils.command.config import config\nfrom tqdm.auto import tqdm\nfrom datetime import timedelta\nfrom datetime import datetime\nimport mlflow\nfrom sklearn.metrics import mean_absolute_error,mean_squared_error\nimport os\nimport logging\nimport dotsi"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"a6a9bce9-50cb-40e2-aa29-ce9cd6d24a22","inputWidgets":{},"title":"Load relevant packages"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# logging part\np_dir = '/tmp/'\nlog_file = \"Prophet_hyperparameter_tuning\" + \" (\" +datetime.today().strftime('%Y-%m-%d-%H-%M-%S')+ \").log\"\n\n# Prophet - Hyperparameter tuning logs\nlogger = logging.getLogger('custom_log')\nlogger.setLevel(logging.DEBUG)\n\n# Applying necessary formatter\nfh = logging.FileHandler(p_dir+log_file)\nformatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\nfh.setFormatter(formatter)\nlogger.addHandler(fh)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"34980505-328f-4e50-8846-2fc7a23bff2e","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Getting the default settings of hyperparameters. Used to check that user-provided hyperparameters must always be a subset of these.\ndef get_default_args(func) -> dict:\n    \"\"\"Function to get the default values of the hyperparameters for the given algorithm\n\n    Parameters\n    ----------\n    func : constructor of the respective algorithm\n        The name of the algorithm (Eg: Prophet,SARIMAX)\n\n    Returns\n    -------\n    dict\n        returns a dictionary of hyperparameters and the corresponding default values for the given algorithm\n    \"\"\"\n    \n    signature = inspect.signature(func)\n    return {\n        k: v.default if v.default is not inspect.Parameter.empty else None\n        for k, v in signature.parameters.items()\n        if k != 'self'\n    }"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3ded48db-f67d-412a-ad56-d3904dfdb24b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Configurable Hyperparameters\nThe following are the possible hyperparameters that can be tuned for Prophet. The preferred hyperparameters, and their respective search spaces, over which tuning is to be done need to be mentioned in the config file."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1f7a8df8-c970-4e89-9529-ac9301c10bbf","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Default values for the hyperparameters in Prophet\ndefault_hpps = get_default_args(Prophet)\ndefault_hpps"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d2101a02-80fb-461a-a858-4a146a61042c","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[139]: {&#39;growth&#39;: &#39;linear&#39;,\n &#39;changepoints&#39;: None,\n &#39;n_changepoints&#39;: 25,\n &#39;changepoint_range&#39;: 0.8,\n &#39;yearly_seasonality&#39;: &#39;auto&#39;,\n &#39;weekly_seasonality&#39;: &#39;auto&#39;,\n &#39;daily_seasonality&#39;: &#39;auto&#39;,\n &#39;holidays&#39;: None,\n &#39;seasonality_mode&#39;: &#39;additive&#39;,\n &#39;seasonality_prior_scale&#39;: 10.0,\n &#39;holidays_prior_scale&#39;: 10.0,\n &#39;changepoint_prior_scale&#39;: 0.05,\n &#39;mcmc_samples&#39;: 0,\n &#39;interval_width&#39;: 0.8,\n &#39;uncertainty_samples&#39;: 1000,\n &#39;stan_backend&#39;: None}</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[139]: {&#39;growth&#39;: &#39;linear&#39;,\n &#39;changepoints&#39;: None,\n &#39;n_changepoints&#39;: 25,\n &#39;changepoint_range&#39;: 0.8,\n &#39;yearly_seasonality&#39;: &#39;auto&#39;,\n &#39;weekly_seasonality&#39;: &#39;auto&#39;,\n &#39;daily_seasonality&#39;: &#39;auto&#39;,\n &#39;holidays&#39;: None,\n &#39;seasonality_mode&#39;: &#39;additive&#39;,\n &#39;seasonality_prior_scale&#39;: 10.0,\n &#39;holidays_prior_scale&#39;: 10.0,\n &#39;changepoint_prior_scale&#39;: 0.05,\n &#39;mcmc_samples&#39;: 0,\n &#39;interval_width&#39;: 0.8,\n &#39;uncertainty_samples&#39;: 1000,\n &#39;stan_backend&#39;: None}</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Broadcast helper functions\nThese functions helps to persist the data in all the workers so that we can leverage them in UDF while distributed processing"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"bf9c7927-7ead-4694-bf9f-346a0ca0fd7a","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["def broadcast_holidays(\n    config_holidays: dict,\n    year_list: list =[2018, 2019, 2020, 2021, 2022],\n    country_name: str =\"US\",\n    holiday_lower_window: int =7,\n    holiday_upper_window: int =7,\n) -> pd.DataFrame:\n    \"\"\"Function to return the dataframe of holidays for the given time period using Prophet's make_holidays_df()\n\n    Parameters\n    ----------\n    config_holidays : dict\n        the additional list of holidays and its respective dates provided by the user in config file\n    year_list : list, optional\n        the list of years for which we need the holidays , by default [2018, 2019, 2020, 2021, 2022]\n    country_name : str, optional\n        Name of the country based on which holidays can be decided, by default \"US\"\n    holiday_lower_window : int, optional\n        lower limit of the window, by default 7\n    holiday_upper_window : int, optional\n        upper limit of the window, by default 7\n\n    Returns\n    -------\n    pd.DataFrame\n        Returns a dataframe of holidays for the given time period\n    \"\"\"\n    holidays = make_holidays_df(year_list, country_name)\n    # Add window\n    holidays['lower_window'] = -holiday_lower_window\n    holidays['upper_window'] = holiday_upper_window\n    \n    # Adding additional holidays\n    if config_holidays is not None:\n        for ad_hol in config_holidays.keys():\n            temp_df = pd.DataFrame({'holiday':ad_hol,\n                                    'ds': pd.to_datetime(config_holidays[ad_hol]['ds']),\n                                    'lower_window': -holiday_lower_window,\n                                    'upper_window': holiday_upper_window})\n            holidays = pd.concat([holidays,temp_df])\n    \n    # Dropping duplicates if exists any\n    holidays = holidays.drop_duplicates().reset_index(drop = True)\n    return holidays"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0a768cd3-d3f1-4c04-8700-69a524f91786","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Processing Config file\nDependent variable, date variable, modeling granularity & other related modeling details are provided in the form of a config file.Each TS Algorithm and the related hyperparameter values to be tried should given in the config.yml file"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2154c025-1057-46f2-a6d6-81e771ee9a6d","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%run ../../../0_Config.ipynb"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"60af8778-946b-4a6b-a7d1-210886a146f3","inputWidgets":{},"title":"Reading the model configuration file"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["logger.info(\"Config file read\")\nassert set(app_config[\"Algorithms\"][\"Prophet\"][\"Hyperparameters\"].keys()).issubset(set(default_hpps.keys())),\\\n           'keys supplied by the user for the Prophet Algorithm under Hyperparameters must be valid'\n\n# For exporting the config file\ntemp_config = app_config.copy()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"faab8457-d5e3-4614-a847-229824275baa","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def frange(start,stop,step= 1):\n    l = []\n    i = start\n    while(i < stop):\n        l.append(round(i,len(str(step))))\n        i = i+step\n    return l\n\ndef drange(hyperparameters):\n    l=[]\n    for key in hyperparameters.keys():\n        val = hyperparameters[key]\n        if 'range' in val:\n            val = val.replace('range','frange')\n            new_str = 'total_list = '  + val\n            _locals = locals()\n            exec(new_str,globals(),_locals)\n            without_dup = list(set(_locals['total_list']))\n            hyperparameters[key] = without_dup\n    return hyperparameters"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"38e0b4bb-9721-4bb4-9deb-47970dc64b75","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["fit_ = drange(app_config[\"Algorithms\"][\"Prophet\"][\"Hyperparameters\"])\nfit_new = {}\nfor key in fit_.keys():\n    temp = []\n    for val in fit_[key]:\n        if(type(val) == list):\n            val = str(val)\n        if((val!='None') and (val!='Null') and (val!=None)):\n            temp.append(val)\n    if(len(temp)>0):\n        fit_new[key] = temp\n        \napp_config[\"Algorithms\"][\"Prophet\"][\"Hyperparameters\"] = fit_new"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"70799201-7fa0-495a-90cf-f716284c5b3e","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Create the algo and logs directory for storing the results\noutput_directory = app_config['output_dir_path']\nroot_dir = \"Modeling_Results\"\nalgorithm = \"Prophet\"\nalgo_path = os.path.join(output_directory,root_dir,algorithm)\nif not os.path.exists(algo_path):\n    os.makedirs(algo_path)\nlogger.info(\"Created algorithm directory\")    \n\nlogs_path = os.path.join(output_directory,root_dir,'logs',algorithm)\nif not os.path.exists(logs_path):\n    os.makedirs(logs_path)\n    \nlogger.info(\"Created logs directory\")\n\nconfig_path = os.path.join(app_config['output_dir_path'],\"Modeling_Results\",\"config\")\nif not os.path.exists(config_path):\n    os.makedirs(config_path)\n    \nlogger.info(\"Created config directory\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"43c8cc35-d69c-4856-9cad-aa27b6bfcfc5","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Broadcasting the required variables\nVariables suffixed with \"_conf\" are taken from the config file"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4cffcf15-ceb5-4848-91a4-c484f8b66912","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["hyperparameters_conf = dict(app_config[\"Algorithms\"][\"Prophet\"][\"Hyperparameters\"])\n# print(hyperparameters_conf)\n\nmodeling_granularity_conf = app_config[\"modeling_granularity\"]\n# print(modeling_granularity_conf)\n\n# Rename Start date and DV config\ndv_config = app_config[\"dependent_variable\"]\nds_config = app_config[\"date_var\"]\n\n# pos and neg corr broadcast\ncorr_config = dict(app_config['Algorithms']['Prophet']['exogenous_variables'])\ncorr_config_broadcast = dotsi.Dict({\"value\":corr_config})\n\n# Eval metric broadcast\nbroadcast_metric = dotsi.Dict({\"value\":app_config[\"validation\"][\"metric\"]})\n\nbroadcast_tracking = dotsi.Dict({\"value\":app_config['tracking']})\nbroadcast_test_periods = dotsi.Dict({\"value\":app_config[\"validation\"][\"no_of_backtesting_test_periods\"]})\n# ===================================================================================\n\n# Broadcasting\nif app_config[\"Algorithms\"][\"Prophet\"][\"Holidays\"][\"include_holidays\"] == True:\n    aa = app_config[\"Algorithms\"][\"Prophet\"][\"Holidays\"]\n    holidays_broadcast = broadcast_holidays(aa['additional_holidays'],aa['years'],aa['country'],aa['holiday_lower_window'],aa['holiday_upper_window'])\n    holidays_broadcast = dotsi.Dict({\"value\":holidays_broadcast})\nelse:\n    holidays_broadcast = dotsi.Dict({\"value\":None})\n    \nbroadcast_regressor_mode = dotsi.Dict({\"value\":app_config[\"Algorithms\"][\"Prophet\"][\"regressor_mode\"]})\nbroadcast_granularity = dotsi.Dict({\"value\":modeling_granularity_conf})\nbroadcast_hyper_parameters = dotsi.Dict({\"value\":hyperparameters_conf})\n\nlogger.info(\"Broadcasted the required variables\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"cefabbdb-dd5a-4cb9-bc6d-548ee044daf2","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Reading feature selected output and using the significant variables as idvs in modeling\nfeature_selection_info = app_config['Algorithms']['Prophet']['feature_selection']\nbroadcast_use_features = dotsi.Dict({\"value\":feature_selection_info['use_feature_selected_idvs']})\nif(feature_selection_info['use_feature_selected_idvs']):\n    if(feature_selection_info['approach']=='lasso_cvglmnet'):\n        output_folder = app_config['output_dir_path']+\"/Feature_Selection/Lasso/\"\n    # Reading the latest input file based on timestamp\n    coeff_op_files = [file for file in os.listdir(output_folder)]\n    coeff_op_files = [file.replace(\".csv\",\"\") for file in coeff_op_files]\n    version_dates = [datetime.strptime(x.split('(')[1].replace(')',''), '%Y-%m-%d-%H-%M-%S') for x in coeff_op_files]\n    max_date = max(version_dates)\n    max_date = max_date.strftime('%Y-%m-%d-%H-%M-%S')\n    req_file_name = [x for x in coeff_op_files if max_date in x]\n    coeff_op_file_path = os.path.join(output_folder,req_file_name[0]+\".csv\")\n    print(coeff_op_file_path)\n\n    # Reading the data\n    coeff_df = pd.read_csv(coeff_op_file_path)\n    coeff_df = coeff_df[coeff_df['status']=='success']\n    # print(coeff_df.shape)\n    coeff_df[modeling_granularity_conf] = coeff_df[modeling_granularity_conf].astype(str)\n    idvs_len = len(feature_selection_info['must_have_idvs'])\n    if(idvs_len>0):\n        temp1 = coeff_df[modeling_granularity_conf].drop_duplicates()\n        temp1['temp'] = 1\n        temp2 = pd.DataFrame({'IDV':feature_selection_info['must_have_idvs']})\n        temp2['temp'] = 1\n        temp = temp1.join(temp2, on = 'temp', how ='left')\n        req_cols = modeling_granularity_conf + ['IDV']\n        coeff_df = coeff_df.drop_duplicates()\n    coeffs_broadcast = dotsi.Dict({\"value\":coeff_df})\n# display(coeff_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"746a973d-d1c9-4f09-bedc-1c1f08028494","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">/dbfs/mnt/solutionsadls_data/modeling_results_python/Feature_Selection/Lasso/lasso_feature_selection_results (2023-01-13-04-31-21).csv\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/dbfs/mnt/solutionsadls_data/modeling_results_python/Feature_Selection/Lasso/lasso_feature_selection_results (2023-01-13-04-31-21).csv\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Pandas UDF for Backtesting\nThe UDF gets executed in multiple worker nodes to parallelize the backtesting process. All the broadcasted variables are accessed within the UDF as and when required"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"53235143-a8d9-4772-8d04-36ae02c61986","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["def get_prediction_UDF(df_data: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Function to perform backtesting for the given input data using the broadcasted information from the config file\n\n    Parameters\n    ----------\n    df_data : pd.DataFrame\n        The dataset containing values for all the required variables\n\n    Returns\n    -------\n    pd.DataFrame\n        Returns a dataframe with the granularity,date,hyperparameters,window and performance metrics\n    \"\"\"\n    try:\n        train_index_start = df_data[\"train_index_start\"].iloc[0]\n        train_index_end = df_data[\"train_index_end\"].iloc[0]\n        test_i = df_data[\"test_index_end\"].iloc[0]\n        window_no = df_data[\"window_no\"].iloc[0]\n        regressor_mode = broadcast_regressor_mode.value\n        \n        df_data = df_data.sort_values(by=['ds'],ascending=True)\n        df_data = df_data.iloc[train_index_start:test_i].reset_index(drop=True)\n\n        # broadcast_granularity\n        broadcast_gran = broadcast_granularity.value\n\n        # Train - test split\n        test_periods = int(broadcast_test_periods.value)\n        train = df_data.iloc[:-test_periods]\n        test = df_data.iloc[-test_periods:]\n\n        # Updating the default arguments with the parameters provided in the config\n        hp_config = broadcast_hyper_parameters.value\n        def_args = get_default_args(Prophet)\n        for x in hp_config:\n            def_args[x] = df_data[x].iloc[0]\n        if holidays_broadcast.value is not None:\n            def_args[\"holidays\"] = holidays_broadcast.value\n        if(regressor_mode not in ['additive','multiplicative']):\n            regressor_mode = def_args['seasonality_mode'] \n        # Calling the Prophet constructor with the hyperparameters of interest\n        m = Prophet(**def_args)\n\n        if(broadcast_use_features.value==True):\n            # Reading regressors from feature selection\n            coeffs_df = coeffs_broadcast.value\n            for x in broadcast_gran:\n                coeffs_df = coeffs_df[coeffs_df[x] == df_data[x].iloc[0]]\n            regressors = list(coeffs_df['IDV'].values)\n        else:\n            # Appending regressors based on the sign of correlation\n            corr_var = corr_config_broadcast.value\n            regressors = list(set(corr_var[\"positive_corr\"] + corr_var[\"negative_corr\"]+corr_var['uncertain_corr']))\n\n            # Removing regressors based on the correlation\n            if(corr_var[\"consider_correlation\"]):    \n                temp_list = []\n                for x in corr_var[\"positive_corr\"]:\n                    if(train[['y',x]].corr().iloc[0][1]<0):\n                        temp_list.append(x)\n                for x in corr_var[\"negative_corr\"]:\n                    if (x not in temp_list):\n                        if(train[['y',x]].corr().iloc[0][1]>0):\n                            temp_list.append(x)   \n                regressors = list(set(regressors) - set(temp_list)) \n            # Checking for variance in the regressor\n            temp_list = []\n            if len(regressors)>0:\n                for ex_var in regressors:\n                    mean = train[ex_var].mean()\n                    std = train[ex_var].std()\n                    if mean == 0:\n                        if std <= 0.001:\n                            temp_list.append(ex_var)\n                    else:\n                        if abs(std/mean) <= 0.01:\n                            temp_list.append(ex_var)\n            regressors = list(set(regressors) - set(temp_list)) \n            \n        for var in regressors:\n            m.add_regressor(var,mode = regressor_mode)    \n        m.fit(train)\n\n        forecast_pd = m.predict(test)\n        results_pd = forecast_pd[[\"ds\", \"yhat\", \"yhat_upper\", \"yhat_lower\"]]\n        results_pd = pd.merge(\n            results_pd, test[[\"y\", \"ds\"] + broadcast_gran], how=\"left\", on=\"ds\"\n        )\n        y_pred = results_pd[\"yhat\"]\n        y_true = results_pd[\"y\"]\n\n        # correct y_pred to 0 if -ve\n        y_pred = np.where(y_pred < 0, 0, y_pred)\n\n        # to handle erroneous results epsilon is set to 1.\n        epsilon = 1\n\n        # Eval. metrics calculation\n        results_pd[\"mape\"] = (np.mean(np.abs(y_true - y_pred) / np.maximum(np.abs(y_true), epsilon)) * 100)\n        results_pd[\"wmape\"] = (np.sum(np.abs(y_true - y_pred))/ np.maximum(np.sum(np.abs(y_true)), epsilon)* 100)\n        results_pd[\"bias\"] = np.mean((y_true - y_pred))\n        results_pd[\"tracking_signal\"] = np.sum((y_true - y_pred)) / np.mean(np.abs(y_true - y_pred))\n        results_pd[\"mae\"] = mean_absolute_error(y_true, y_pred)\n        results_pd[\"rmse\"] = np.sqrt(mean_squared_error(y_true, y_pred))\n\n        # To adhere to defined schema\n        for x in broadcast_gran:\n            results_pd[x] = results_pd[x].astype(str)\n\n        # Append Hyperparameters used\n        for x in hp_config:\n            results_pd[x] = df_data[x].iloc[0]\n\n        results_pd[\"window\"] = str(str(train_index_start)+\" \"+str(train_index_end)+\" \"+str(test_i)+\" \"+str(window_no))\n\n        # Sales or Quantity can't be negative hence\n        results_pd[\"yhat\"] = np.where(results_pd[\"yhat\"] < 0, 0, results_pd[\"yhat\"])\n        results_pd[\"yhat_upper\"] = np.where(results_pd[\"yhat_upper\"] < 0, 0, results_pd[\"yhat_upper\"])\n        results_pd[\"yhat_lower\"] = np.where(results_pd[\"yhat_lower\"] < 0, 0, results_pd[\"yhat_lower\"])\n        results_pd[\"status\"] = \"success\"\n        return results_pd\n\n    except Exception as e:\n        results_pd = pd.DataFrame(columns=[[\"ds\",\"y\",\"yhat\",\"yhat_upper\",\"yhat_lower\",\"mape\",\"wmape\",\"bias\",\"tracking_signal\",\"mae\",\"rmse\",\"window\"]+\\\n                                           list(broadcast_hyper_parameters.value.keys())+[\"status\"]+ broadcast_granularity.value],index=range(1))\n        results_pd[broadcast_granularity.value] = df_data[broadcast_granularity.value].head(1).reset_index(drop=True)\n        for x in broadcast_granularity.value:\n            results_pd[x] = results_pd[x].astype(str)\n        results_pd[\"status\"] = str(e)\n        return results_pd"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8c969087-f184-4230-8afd-d546dbf2fae2","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Hyperparameter grid\nThe following function creates a cross product of all the hyperparameters provided in the config file and returns a hyperparamter grid"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"83f16e33-ba7b-4b59-aab5-af7502db75d0","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Creating a hyperparameter grid using the set of provided hyperparameters in the config file\ndef create_hyperparam_space(hp_space: dict) -> pd.DataFrame:\n    \"\"\"Function to create a hyperparameter grid using the set of provided hyperparameters in the config file to be used for Hyperparameter tuning\n\n    Parameters\n    ----------\n    hp_space : dict\n        The set of provided hyperparameters in the config file\n\n    Returns\n    -------\n    pd.DataFrame\n        Returns a hyperparameter grid created from the set of provided hyperparameters\n    \"\"\"    \n    df_list = list()\n    for x in hp_space:\n        df_list.append(pd.DataFrame({x:hp_space[x]}))\n\n    space=df_list[0]\n\n    for x in df_list[1:]:\n        space = space.merge(x,how=\"cross\")\n\n    return space"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1e206e9b-e104-4063-bdc7-e552d42811d8","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Backtesting parallelized using UDF\nBased on the Backtesting algorithm (sliding_window/expanding_window), training percentage & test periods specified in the config file, Hyperparameter tuning is performed"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9f764ca6-c6e6-4571-8432-abebb0d66dcd","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["def hyperparameter_tuning(\n    algorithm: str,\n    train_data: pd.DataFrame,\n    hyperparam_space: dict,\n    modeling_granularity_conf: list,\n    train_percentage: float,\n    backtesting_test_periods: int,\n    test_periods: int,\n    stride: int,\n    modelling_func: pd.DataFrame = get_prediction_UDF,\n) -> pd.DataFrame:\n    \n    \"\"\"Function to perform the hyperparameter tuning\n\n    Parameters\n    ----------\n    algorithm : str\n        the algorithm with which the hyperparameter tuning is to be performed(sliding_window/expanding_window)\n    train_data : pd.DataFrame\n        the modelling dataset\n    hyperparam_space : dict\n        hyperparameter grid which was created using the set of hyperparameter from config file\n    modeling_granularity_conf : list\n        The list of the granularity variables at which the models will be built\n    train_percentage : float\n        The percentage of data points for the training\n    backtesting_test_periods : int\n        number of time periods to score in each iteration of backtesting\n    test_periods : int\n        number of time periods to score in final model building\n    stride : int\n        number of time periods to stride in each iteration of Backtesting\n    modelling_func : pd.DataFrame, optional\n        the function name to perform backtesting for the given dataset, by default get_prediction_UDF\n\n    Returns\n    -------\n    pd.DataFrame\n        Returns the dataframe containing the hyperparameter set of modelling granularity x hyperparameter set x window level\n    \"\"\"\n    if algorithm == \"expanding_window\":\n        gbcp = list(modeling_granularity_conf) + list(hyperparam_space.columns)\n        unique_skuXds = train_data[modeling_granularity_conf+[\"#total_weeks\"]].drop_duplicates().reset_index(drop = True)\n        \n        final_list = []\n        gran_len = len(modeling_granularity_conf)\n        for row1 in range(0,len(unique_skuXds)): \n            Total_weeks = unique_skuXds.loc[row1,'#total_weeks']\n            train_interval = int((Total_weeks-test_periods) * train_percentage)\n            j = 0\n            train_period_ends = Total_weeks-test_periods\n            for train_i in range(train_interval,train_period_ends,stride):\n                if(train_i+backtesting_test_periods <=train_period_ends):\n                    test_i = train_i+backtesting_test_periods\n                    final_list.append([unique_skuXds.iloc[row1,index] for index in range(gran_len)] + [0,train_i,train_i+backtesting_test_periods,j+1])\n                    j += 1\n                    \n        # create all windows combination.\n        df_windows = pd.DataFrame([tuple(x) for x in final_list],columns =modeling_granularity_conf+\\\n                                  ['train_index_start','train_index_end','test_index_end','window_no'])\n        f_df = train_data.merge(df_windows,on=modeling_granularity_conf,how=\"left\")\n        f_df['temppp'] = 1\n        hyperparam_space['temppp'] = 1\n        f_df = f_df.merge(hyperparam_space,on='temppp',how=\"left\")\n        f_df['gran_tempp'] = f_df[gbcp+[\"train_index_start\",\"train_index_end\",\"test_index_end\",\"window_no\"]].astype(str).sum(axis=1)\n        unique_pdts = f_df['gran_tempp'].unique()\n        new_results = pd.DataFrame()\n        for pdt in unique_pdts:\n            new_results = pd.concat([new_results,modelling_func(f_df[f_df['gran_tempp']==pdt])])\n        return new_results\n    \n    elif algorithm == \"sliding_window\":\n        gbcp = list(modeling_granularity_conf) + list(hyperparam_space.columns)\n        unique_skuXds = train_data[modeling_granularity_conf+[\"#total_weeks\"]].drop_duplicates().reset_index(drop = True)\n        \n        final_list = []\n        gran_len = len(modeling_granularity_conf)\n        for row1 in range(0,len(unique_skuXds)): \n            Total_weeks = unique_skuXds.loc[row1,'#total_weeks']\n            train_interval = int((Total_weeks-test_periods) * train_percentage)\n            j = 0\n            train_period_ends = Total_weeks-test_periods\n            train_index_start = 0\n            for train_i in range(train_interval,train_period_ends,stride):\n                if(train_i+backtesting_test_periods <=train_period_ends):\n                    test_i = train_i+backtesting_test_periods\n                    final_list.append([unique_skuXds.iloc[row1,index] for index in range(gran_len)] + \\\n                                      [train_index_start,train_i,train_i+backtesting_test_periods,j+1])\n                    j += 1\n                    train_index_start = train_index_start+stride\n                    \n        # create all windows combination.\n        df_windows = pd.DataFrame([tuple(x) for x in final_list],columns =modeling_granularity_conf+\\\n                                  ['train_index_start','train_index_end','test_index_end','window_no'])\n        f_df = train_data.merge(df_windows,on=modeling_granularity_conf,how=\"left\")\n        f_df['temppp'] = 1\n        hyperparam_space['temppp'] = 1\n        f_df = f_df.merge(hyperparam_space,on='temppp',how=\"left\")\n        f_df['gran_tempp'] = f_df[gbcp+[\"train_index_start\",\"train_index_end\",\"test_index_end\",\"window_no\"]].astype(str).sum(axis=1)\n        unique_pdts = f_df['gran_tempp'].unique()\n        new_results = pd.DataFrame()\n        for pdt in unique_pdts:\n            new_results = pd.concat([new_results,modelling_func(f_df[f_df['gran_tempp']==pdt])])\n        return new_results"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"67017b18-847a-4a04-950e-c5fa6c78b0c6","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Loading the latest Missing_value_treatment file\n##### Please update the reading path with the required data path if \"Missing value treatment\" was not run"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"98bf141c-0cee-4e7a-821b-393a3b5a2a64","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Reading the latest input file based on timestamp\nall_files = [file for file in os.listdir(app_config['output_dir_path']+\"/Data_Processing/Missing_value_treatment\")]\nmissing_op_files = [file for file in all_files if \"Missing_value_treatment_results (\" in file]\nmissing_op_files = [file.replace(\".csv\",\"\") for file in missing_op_files]\nversion_dates = [datetime.strptime(x.split('(')[1].replace(')',''), '%Y-%m-%d-%H-%M-%S') for x in missing_op_files]\nmax_date = max(version_dates)\nmax_date = max_date.strftime('%Y-%m-%d-%H-%M-%S')\nreq_file_name = [x for x in missing_op_files if max_date in x]\nmissing_op_file_path = os.path.join(app_config['output_dir_path']+\"/Data_Processing/Missing_value_treatment\",req_file_name[0] + \".csv\")\n# print(missing_op_file_path)\n\n# Reading the data\ndf = pd.read_csv(missing_op_file_path)\n# print(df.shape)\n\ndf.rename(columns = {ds_config:\"ds\", dv_config:\"y\"}, inplace = True)\nlogger.info(\"Data loaded\")\n\ndf['ds'] = pd.to_datetime(df['ds'])\ndf[modeling_granularity_conf] = df[modeling_granularity_conf].astype(str)\n\n# Getting the total number of weeks for each time series\ntemp_df = df.groupby(modeling_granularity_conf).agg({'ds':'count'}).rename(columns={'ds': '#total_weeks'}).reset_index()\ndf = df.merge(temp_df, on = modeling_granularity_conf ,how = \"left\")\n\n# 2. Create the hyperparameter space\nhpspace = create_hyperparam_space(hyperparameters_conf)\nlogger.info(\"Created hyperparameter grid\")\n\n# 4.  HP tuning based on algorithm of choice\ndf_f = hyperparameter_tuning(app_config['validation']['backtesting']['algorithm'],\\\n                             df,hpspace,modeling_granularity_conf,\\\n                             app_config['validation']['train_percentage'],\\\n                             app_config['validation']['no_of_backtesting_test_periods'],\\\n                             app_config['validation']['no_of_test_periods'],\\\n                             app_config['validation']['backtesting']['stride'],modelling_func = get_prediction_UDF)\n\nif holidays_broadcast.value is not None:\n    holidays_df = holidays_broadcast.value\n    holidays_df[\"ds\"] = holidays_df[\"ds\"].astype(str)\n    df_f['holidays'] = holidays_df.reset_index(drop = True).to_json()\ndf_f.to_csv(algo_path + \"/Backtesting_results_window_level (\" + datetime.today().strftime('%Y-%m-%d-%H-%M-%S')+\").csv\", index = False)\nlogger.info(\"Completed Backtesting\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fed65c4e-f2c4-4ad7-817a-f3d8dc433183","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">05:23:18 - cmdstanpy - INFO - Chain [1] start processing\n05:23:20 - cmdstanpy - INFO - Chain [1] done processing\n05:23:23 - cmdstanpy - INFO - Chain [1] start processing\n05:23:23 - cmdstanpy - INFO - Chain [1] done processing\n05:23:26 - cmdstanpy - INFO - Chain [1] start processing\n05:23:26 - cmdstanpy - INFO - Chain [1] done processing\n05:23:28 - cmdstanpy - INFO - Chain [1] start processing\n05:23:28 - cmdstanpy - INFO - Chain [1] done processing\n05:23:31 - cmdstanpy - INFO - Chain [1] start processing\n05:23:32 - cmdstanpy - INFO - Chain [1] done processing\n05:23:32 - cmdstanpy - ERROR - Chain [1] error: error during processing Communication error on send\nOptimization terminated abnormally. Falling back to Newton.\n05:23:32 - cmdstanpy - INFO - Chain [1] start processing\n05:23:36 - cmdstanpy - INFO - Chain [1] done processing\n05:23:38 - cmdstanpy - INFO - Chain [1] start processing\n05:23:38 - cmdstanpy - INFO - Chain [1] done processing\n05:23:41 - cmdstanpy - INFO - Chain [1] start processing\n05:23:41 - cmdstanpy - INFO - Chain [1] done processing\n05:23:41 - cmdstanpy - ERROR - Chain [1] error: error during processing Communication error on send\nOptimization terminated abnormally. Falling back to Newton.\n05:23:41 - cmdstanpy - INFO - Chain [1] start processing\n05:23:45 - cmdstanpy - INFO - Chain [1] done processing\n05:23:47 - cmdstanpy - INFO - Chain [1] start processing\n05:23:47 - cmdstanpy - INFO - Chain [1] done processing\n05:23:50 - cmdstanpy - INFO - Chain [1] start processing\n05:23:50 - cmdstanpy - INFO - Chain [1] done processing\n05:23:53 - cmdstanpy - INFO - Chain [1] start processing\n05:23:53 - cmdstanpy - INFO - Chain [1] done processing\n05:23:56 - cmdstanpy - INFO - Chain [1] start processing\n05:23:56 - cmdstanpy - INFO - Chain [1] done processing\n05:23:58 - cmdstanpy - INFO - Chain [1] start processing\n05:23:58 - cmdstanpy - INFO - Chain [1] done processing\n05:24:01 - cmdstanpy - INFO - Chain [1] start processing\n05:24:01 - cmdstanpy - INFO - Chain [1] done processing\n05:24:03 - cmdstanpy - INFO - Chain [1] start processing\n05:24:03 - cmdstanpy - INFO - Chain [1] done processing\n05:24:06 - cmdstanpy - INFO - Chain [1] start processing\n05:24:06 - cmdstanpy - INFO - Chain [1] done processing\n05:24:09 - cmdstanpy - INFO - Chain [1] start processing\n05:24:09 - cmdstanpy - INFO - Chain [1] done processing\n05:24:11 - cmdstanpy - INFO - Chain [1] start processing\n05:24:11 - cmdstanpy - INFO - Chain [1] done processing\n05:24:14 - cmdstanpy - INFO - Chain [1] start processing\n05:24:14 - cmdstanpy - INFO - Chain [1] done processing\n05:24:16 - cmdstanpy - INFO - Chain [1] start processing\n05:24:16 - cmdstanpy - INFO - Chain [1] done processing\n05:24:19 - cmdstanpy - INFO - Chain [1] start processing\n05:24:19 - cmdstanpy - INFO - Chain [1] done processing\n05:24:21 - cmdstanpy - INFO - Chain [1] start processing\n05:24:21 - cmdstanpy - INFO - Chain [1] done processing\n05:24:24 - cmdstanpy - INFO - Chain [1] start processing\n05:24:24 - cmdstanpy - INFO - Chain [1] done processing\n05:24:26 - cmdstanpy - INFO - Chain [1] start processing\n05:24:26 - cmdstanpy - INFO - Chain [1] done processing\n05:24:29 - cmdstanpy - INFO - Chain [1] start processing\n05:24:29 - cmdstanpy - INFO - Chain [1] done processing\n05:24:31 - cmdstanpy - INFO - Chain [1] start processing\n05:24:31 - cmdstanpy - INFO - Chain [1] done processing\n05:24:34 - cmdstanpy - INFO - Chain [1] start processing\n05:24:34 - cmdstanpy - INFO - Chain [1] done processing\n05:24:37 - cmdstanpy - INFO - Chain [1] start processing\n05:24:37 - cmdstanpy - INFO - Chain [1] done processing\n05:24:39 - cmdstanpy - INFO - Chain [1] start processing\n05:24:39 - cmdstanpy - INFO - Chain [1] done processing\n05:24:42 - cmdstanpy - INFO - Chain [1] start processing\n05:24:42 - cmdstanpy - INFO - Chain [1] done processing\n05:24:45 - cmdstanpy - INFO - Chain [1] start processing\n05:24:45 - cmdstanpy - INFO - Chain [1] done processing\n05:24:47 - cmdstanpy - INFO - Chain [1] start processing\n05:24:47 - cmdstanpy - INFO - Chain [1] done processing\n05:24:50 - cmdstanpy - INFO - Chain [1] start processing\n05:24:50 - cmdstanpy - INFO - Chain [1] done processing\n05:24:53 - cmdstanpy - INFO - Chain [1] start processing\n05:24:53 - cmdstanpy - INFO - Chain [1] done processing\n05:24:55 - cmdstanpy - INFO - Chain [1] start processing\n05:24:55 - cmdstanpy - INFO - Chain [1] done processing\n05:24:58 - cmdstanpy - INFO - Chain [1] start processing\n05:24:58 - cmdstanpy - INFO - Chain [1] done processing\n05:25:00 - cmdstanpy - INFO - Chain [1] start processing\n05:25:01 - cmdstanpy - INFO - Chain [1] done processing\n05:25:03 - cmdstanpy - INFO - Chain [1] start processing\n05:25:03 - cmdstanpy - INFO - Chain [1] done processing\n05:25:06 - cmdstanpy - INFO - Chain [1] start processing\n05:25:06 - cmdstanpy - INFO - Chain [1] done processing\n05:25:09 - cmdstanpy - INFO - Chain [1] start processing\n05:25:09 - cmdstanpy - INFO - Chain [1] done processing\n05:25:12 - cmdstanpy - INFO - Chain [1] start processing\n05:25:12 - cmdstanpy - INFO - Chain [1] done processing\n05:25:14 - cmdstanpy - INFO - Chain [1] start processing\n05:25:14 - cmdstanpy - INFO - Chain [1] done processing\n05:25:17 - cmdstanpy - INFO - Chain [1] start processing\n05:25:17 - cmdstanpy - INFO - Chain [1] done processing\n05:25:19 - cmdstanpy - INFO - Chain [1] start processing\n05:25:19 - cmdstanpy - INFO - Chain [1] done processing\n05:25:22 - cmdstanpy - INFO - Chain [1] start processing\n05:25:22 - cmdstanpy - INFO - Chain [1] done processing\n05:25:25 - cmdstanpy - INFO - Chain [1] start processing\n05:25:25 - cmdstanpy - INFO - Chain [1] done processing\n05:25:28 - cmdstanpy - INFO - Chain [1] start processing\n05:25:28 - cmdstanpy - INFO - Chain [1] done processing\n05:25:30 - cmdstanpy - INFO - Chain [1] start processing\n05:25:30 - cmdstanpy - INFO - Chain [1] done processing\n05:25:33 - cmdstanpy - INFO - Chain [1] start processing\n05:25:33 - cmdstanpy - INFO - Chain [1] done processing\n05:25:35 - cmdstanpy - INFO - Chain [1] start processing\n05:25:36 - cmdstanpy - INFO - Chain [1] done processing\n05:25:38 - cmdstanpy - INFO - Chain [1] start processing\n05:25:38 - cmdstanpy - INFO - Chain [1] done processing\n05:25:41 - cmdstanpy - INFO - Chain [1] start processing\n05:25:41 - cmdstanpy - INFO - Chain [1] done processing\n05:25:43 - cmdstanpy - INFO - Chain [1] start processing\n05:25:43 - cmdstanpy - INFO - Chain [1] done processing\n05:25:46 - cmdstanpy - INFO - Chain [1] start processing\n05:25:46 - cmdstanpy - INFO - Chain [1] done processing\n05:25:48 - cmdstanpy - INFO - Chain [1] start processing\n05:25:48 - cmdstanpy - INFO - Chain [1] done processing\n05:25:51 - cmdstanpy - INFO - Chain [1] start processing\n05:25:51 - cmdstanpy - INFO - Chain [1] done processing\n05:25:53 - cmdstanpy - INFO - Chain [1] start processing\n05:25:54 - cmdstanpy - INFO - Chain [1] done processing\n05:25:56 - cmdstanpy - INFO - Chain [1] start processing\n05:25:56 - cmdstanpy - INFO - Chain [1] done processing\n05:25:59 - cmdstanpy - INFO - Chain [1] start processing\n05:25:59 - cmdstanpy - INFO - Chain [1] done processing\n05:26:01 - cmdstanpy - INFO - Chain [1] start processing\n05:26:01 - cmdstanpy - INFO - Chain [1] done processing\n05:26:04 - cmdstanpy - INFO - Chain [1] start processing\n05:26:04 - cmdstanpy - INFO - Chain [1] done processing\n05:26:06 - cmdstanpy - INFO - Chain [1] start processing\n05:26:06 - cmdstanpy - INFO - Chain [1] done processing\n05:26:09 - cmdstanpy - INFO - Chain [1] start processing\n05:26:09 - cmdstanpy - INFO - Chain [1] done processing\n05:26:12 - cmdstanpy - INFO - Chain [1] start processing\n05:26:12 - cmdstanpy - INFO - Chain [1] done processing\n05:26:14 - cmdstanpy - INFO - Chain [1] start processing\n05:26:14 - cmdstanpy - INFO - Chain [1] done processing\n05:26:17 - cmdstanpy - INFO - Chain [1] start processing\n05:26:17 - cmdstanpy - INFO - Chain [1] done processing\n05:26:19 - cmdstanpy - INFO - Chain [1] start processing\n05:26:19 - cmdstanpy - INFO - Chain [1] done processing\n05:26:22 - cmdstanpy - INFO - Chain [1] start processing\n05:26:22 - cmdstanpy - INFO - Chain [1] done processing\n05:26:25 - cmdstanpy - INFO - Chain [1] start processing\n05:26:25 - cmdstanpy - INFO - Chain [1] done processing\n05:26:27 - cmdstanpy - INFO - Chain [1] start processing\n05:26:27 - cmdstanpy - INFO - Chain [1] done processing\n05:26:30 - cmdstanpy - INFO - Chain [1] start processing\n05:26:30 - cmdstanpy - INFO - Chain [1] done processing\n05:26:32 - cmdstanpy - INFO - Chain [1] start processing\n05:26:32 - cmdstanpy - INFO - Chain [1] done processing\n05:26:35 - cmdstanpy - INFO - Chain [1] start processing\n05:26:35 - cmdstanpy - INFO - Chain [1] done processing\n05:26:37 - cmdstanpy - INFO - Chain [1] start processing\n05:26:37 - cmdstanpy - INFO - Chain [1] done processing\n05:26:40 - cmdstanpy - INFO - Chain [1] start processing\n05:26:40 - cmdstanpy - INFO - Chain [1] done processing\n05:26:43 - cmdstanpy - INFO - Chain [1] start processing\n05:26:43 - cmdstanpy - INFO - Chain [1] done processing\n05:26:45 - cmdstanpy - INFO - Chain [1] start processing\n05:26:45 - cmdstanpy - INFO - Chain [1] done processing\n05:26:48 - cmdstanpy - INFO - Chain [1] start processing\n05:26:48 - cmdstanpy - INFO - Chain [1] done processing\n05:26:50 - cmdstanpy - INFO - Chain [1] start processing\n05:26:50 - cmdstanpy - INFO - Chain [1] done processing\n05:26:53 - cmdstanpy - INFO - Chain [1] start processing\n05:26:53 - cmdstanpy - INFO - Chain [1] done processing\n05:26:56 - cmdstanpy - INFO - Chain [1] start processing\n05:26:56 - cmdstanpy - INFO - Chain [1] done processing\n05:26:58 - cmdstanpy - INFO - Chain [1] start processing\n05:26:58 - cmdstanpy - INFO - Chain [1] done processing\n05:27:01 - cmdstanpy - INFO - Chain [1] start processing\n05:27:01 - cmdstanpy - INFO - Chain [1] done processing\n05:27:03 - cmdstanpy - INFO - Chain [1] start processing\n05:27:03 - cmdstanpy - INFO - Chain [1] done processing\n05:27:06 - cmdstanpy - INFO - Chain [1] start processing\n05:27:06 - cmdstanpy - INFO - Chain [1] done processing\n05:27:09 - cmdstanpy - INFO - Chain [1] start processing\n05:27:09 - cmdstanpy - INFO - Chain [1] done processing\n05:27:11 - cmdstanpy - INFO - Chain [1] start processing\n05:27:11 - cmdstanpy - INFO - Chain [1] done processing\n05:27:14 - cmdstanpy - INFO - Chain [1] start processing\n05:27:14 - cmdstanpy - INFO - Chain [1] done processing\n05:27:16 - cmdstanpy - INFO - Chain [1] start processing\n05:27:16 - cmdstanpy - INFO - Chain [1] done processing\n05:27:19 - cmdstanpy - INFO - Chain [1] start processing\n05:27:19 - cmdstanpy - INFO - Chain [1] done processing\n05:27:21 - cmdstanpy - INFO - Chain [1] start processing\n05:27:21 - cmdstanpy - INFO - Chain [1] done processing\n05:27:24 - cmdstanpy - INFO - Chain [1] start processing\n05:27:24 - cmdstanpy - INFO - Chain [1] done processing\n05:27:26 - cmdstanpy - INFO - Chain [1] start processing\n05:27:27 - cmdstanpy - INFO - Chain [1] done processing\n05:27:29 - cmdstanpy - INFO - Chain [1] start processing\n05:27:29 - cmdstanpy - INFO - Chain [1] done processing\n05:27:32 - cmdstanpy - INFO - Chain [1] start processing\n05:27:32 - cmdstanpy - INFO - Chain [1] done processing\n05:27:34 - cmdstanpy - INFO - Chain [1] start processing\n05:27:34 - cmdstanpy - INFO - Chain [1] done processing\n05:27:37 - cmdstanpy - INFO - Chain [1] start processing\n05:27:37 - cmdstanpy - INFO - Chain [1] done processing\n05:27:40 - cmdstanpy - INFO - Chain [1] start processing\n05:27:40 - cmdstanpy - INFO - Chain [1] done processing\n05:27:43 - cmdstanpy - INFO - Chain [1] start processing\n05:27:43 - cmdstanpy - INFO - Chain [1] done processing\n05:27:45 - cmdstanpy - INFO - Chain [1] start processing\n05:27:45 - cmdstanpy - INFO - Chain [1] done processing\n05:27:48 - cmdstanpy - INFO - Chain [1] start processing\n05:27:48 - cmdstanpy - INFO - Chain [1] done processing\n05:27:50 - cmdstanpy - INFO - Chain [1] start processing\n05:27:50 - cmdstanpy - INFO - Chain [1] done processing\n05:27:53 - cmdstanpy - INFO - Chain [1] start processing\n05:27:53 - cmdstanpy - INFO - Chain [1] done processing\n05:27:56 - cmdstanpy - INFO - Chain [1] start processing\n05:27:56 - cmdstanpy - INFO - Chain [1] done processing\n05:27:58 - cmdstanpy - INFO - Chain [1] start processing\n05:27:58 - cmdstanpy - INFO - Chain [1] done processing\n05:28:01 - cmdstanpy - INFO - Chain [1] start processing\n05:28:01 - cmdstanpy - INFO - Chain [1] done processing\n05:28:03 - cmdstanpy - INFO - Chain [1] start processing\n05:28:03 - cmdstanpy - INFO - Chain [1] done processing\n05:28:06 - cmdstanpy - INFO - Chain [1] start processing\n05:28:06 - cmdstanpy - INFO - Chain [1] done processing\n05:28:08 - cmdstanpy - INFO - Chain [1] start processing\n05:28:08 - cmdstanpy - INFO - Chain [1] done processing\n05:28:11 - cmdstanpy - INFO - Chain [1] start processing\n05:28:12 - cmdstanpy - INFO - Chain [1] done processing\n05:28:14 - cmdstanpy - INFO - Chain [1] start processing\n05:28:14 - cmdstanpy - INFO - Chain [1] done processing\n05:28:17 - cmdstanpy - INFO - Chain [1] start processing\n05:28:17 - cmdstanpy - INFO - Chain [1] done processing\n05:28:19 - cmdstanpy - INFO - Chain [1] start processing\n05:28:19 - cmdstanpy - INFO - Chain [1] done processing\n05:28:22 - cmdstanpy - INFO - Chain [1] start processing\n05:28:22 - cmdstanpy - INFO - Chain [1] done processing\n05:28:24 - cmdstanpy - INFO - Chain [1] start processing\n05:28:24 - cmdstanpy - INFO - Chain [1] done processing\n05:28:27 - cmdstanpy - INFO - Chain [1] start processing\n05:28:27 - cmdstanpy - INFO - Chain [1] done processing\n05:28:29 - cmdstanpy - INFO - Chain [1] start processing\n05:28:29 - cmdstanpy - INFO - Chain [1] done processing\n05:28:32 - cmdstanpy - INFO - Chain [1] start processing\n05:28:32 - cmdstanpy - INFO - Chain [1] done processing\n05:28:34 - cmdstanpy - INFO - Chain [1] start processing\n05:28:34 - cmdstanpy - INFO - Chain [1] done processing\n05:28:37 - cmdstanpy - INFO - Chain [1] start processing\n05:28:37 - cmdstanpy - INFO - Chain [1] done processing\n05:28:39 - cmdstanpy - INFO - Chain [1] start processing\n05:28:39 - cmdstanpy - INFO - Chain [1] done processing\n05:28:42 - cmdstanpy - INFO - Chain [1] start processing\n05:28:42 - cmdstanpy - INFO - Chain [1] done processing\n05:28:44 - cmdstanpy - INFO - Chain [1] start processing\n05:28:45 - cmdstanpy - INFO - Chain [1] done processing\n05:28:47 - cmdstanpy - INFO - Chain [1] start processing\n05:28:47 - cmdstanpy - INFO - Chain [1] done processing\n05:28:50 - cmdstanpy - INFO - Chain [1] start processing\n05:28:50 - cmdstanpy - INFO - Chain [1] done processing\n05:28:52 - cmdstanpy - INFO - Chain [1] start processing\n05:28:52 - cmdstanpy - INFO - Chain [1] done processing\n05:28:55 - cmdstanpy - INFO - Chain [1] start processing\n05:28:55 - cmdstanpy - INFO - Chain [1] done processing\n05:28:57 - cmdstanpy - INFO - Chain [1] start processing\n05:28:57 - cmdstanpy - INFO - Chain [1] done processing\n05:29:00 - cmdstanpy - INFO - Chain [1] start processing\n05:29:00 - cmdstanpy - INFO - Chain [1] done processing\n05:29:03 - cmdstanpy - INFO - Chain [1] start processing\n05:29:03 - cmdstanpy - INFO - Chain [1] done processing\n05:29:05 - cmdstanpy - INFO - Chain [1] start processing\n05:29:05 - cmdstanpy - INFO - Chain [1] done processing\n05:29:08 - cmdstanpy - INFO - Chain [1] start processing\n05:29:08 - cmdstanpy - INFO - Chain [1] done processing\n05:29:10 - cmdstanpy - INFO - Chain [1] start processing\n05:29:10 - cmdstanpy - INFO - Chain [1] done processing\n05:29:13 - cmdstanpy - INFO - Chain [1] start processing\n05:29:13 - cmdstanpy - INFO - Chain [1] done processing\n05:29:15 - cmdstanpy - INFO - Chain [1] start processing\n05:29:16 - cmdstanpy - INFO - Chain [1] done processing\n05:29:18 - cmdstanpy - INFO - Chain [1] start processing\n05:29:18 - cmdstanpy - INFO - Chain [1] done processing\n05:29:21 - cmdstanpy - INFO - Chain [1] start processing\n05:29:21 - cmdstanpy - INFO - Chain [1] done processing\n05:29:24 - cmdstanpy - INFO - Chain [1] start processing\n05:29:24 - cmdstanpy - INFO - Chain [1] done processing\n05:29:26 - cmdstanpy - INFO - Chain [1] start processing\n05:29:26 - cmdstanpy - INFO - Chain [1] done processing\n05:29:29 - cmdstanpy - INFO - Chain [1] start processing\n05:29:29 - cmdstanpy - INFO - Chain [1] done processing\n05:29:31 - cmdstanpy - INFO - Chain [1] start processing\n05:29:31 - cmdstanpy - INFO - Chain [1] done processing\n05:29:34 - cmdstanpy - INFO - Chain [1] start processing\n05:29:34 - cmdstanpy - INFO - Chain [1] done processing\n05:29:36 - cmdstanpy - INFO - Chain [1] start processing\n05:29:36 - cmdstanpy - INFO - Chain [1] done processing\n05:29:39 - cmdstanpy - INFO - Chain [1] start processing\n05:29:39 - cmdstanpy - INFO - Chain [1] done processing\n05:29:41 - cmdstanpy - INFO - Chain [1] start processing\n05:29:41 - cmdstanpy - INFO - Chain [1] done processing\n05:29:44 - cmdstanpy - INFO - Chain [1] start processing\n05:29:44 - cmdstanpy - INFO - Chain [1] done processing\n05:29:47 - cmdstanpy - INFO - Chain [1] start processing\n05:29:47 - cmdstanpy - INFO - Chain [1] done processing\n05:29:49 - cmdstanpy - INFO - Chain [1] start processing\n05:29:49 - cmdstanpy - INFO - Chain [1] done processing\n05:29:52 - cmdstanpy - INFO - Chain [1] start processing\n05:29:52 - cmdstanpy - INFO - Chain [1] done processing\n05:29:54 - cmdstanpy - INFO - Chain [1] start processing\n05:29:54 - cmdstanpy - INFO - Chain [1] done processing\n05:29:57 - cmdstanpy - INFO - Chain [1] start processing\n05:29:57 - cmdstanpy - INFO - Chain [1] done processing\n05:30:00 - cmdstanpy - INFO - Chain [1] start processing\n05:30:00 - cmdstanpy - INFO - Chain [1] done processing\n05:30:03 - cmdstanpy - INFO - Chain [1] start processing\n05:30:03 - cmdstanpy - INFO - Chain [1] done processing\n05:30:06 - cmdstanpy - INFO - Chain [1] start processing\n05:30:06 - cmdstanpy - INFO - Chain [1] done processing\n05:30:08 - cmdstanpy - INFO - Chain [1] start processing\n05:30:09 - cmdstanpy - INFO - Chain [1] done processing\n05:30:14 - cmdstanpy - INFO - Chain [1] start processing\n05:30:14 - cmdstanpy - INFO - Chain [1] done processing\n05:30:16 - cmdstanpy - INFO - Chain [1] start processing\n05:30:16 - cmdstanpy - INFO - Chain [1] done processing\n05:30:19 - cmdstanpy - INFO - Chain [1] start processing\n05:30:19 - cmdstanpy - INFO - Chain [1] done processing\n05:30:21 - cmdstanpy - INFO - Chain [1] start processing\n05:30:21 - cmdstanpy - INFO - Chain [1] done processing\n05:30:24 - cmdstanpy - INFO - Chain [1] start processing\n05:30:24 - cmdstanpy - INFO - Chain [1] done processing\n05:30:26 - cmdstanpy - INFO - Chain [1] start processing\n05:30:26 - cmdstanpy - INFO - Chain [1] done processing\n05:30:29 - cmdstanpy - INFO - Chain [1] start processing\n05:30:29 - cmdstanpy - INFO - Chain [1] done processing\n05:30:31 - cmdstanpy - INFO - Chain [1] start processing\n05:30:31 - cmdstanpy - INFO - Chain [1] done processing\n05:30:34 - cmdstanpy - INFO - Chain [1] start processing\n05:30:34 - cmdstanpy - INFO - Chain [1] done processing\n05:30:37 - cmdstanpy - INFO - Chain [1] start processing\n05:30:37 - cmdstanpy - INFO - Chain [1] done processing\n05:30:39 - cmdstanpy - INFO - Chain [1] start processing\n05:30:39 - cmdstanpy - INFO - Chain [1] done processing\n05:30:42 - cmdstanpy - INFO - Chain [1] start processing\n05:30:42 - cmdstanpy - INFO - Chain [1] done processing\n05:30:45 - cmdstanpy - INFO - Chain [1] start processing\n05:30:45 - cmdstanpy - INFO - Chain [1] done processing\n05:30:47 - cmdstanpy - INFO - Chain [1] start processing\n05:30:47 - cmdstanpy - INFO - Chain [1] done processing\n05:30:50 - cmdstanpy - INFO - Chain [1] start processing\n05:30:50 - cmdstanpy - INFO - Chain [1] done processing\n05:30:52 - cmdstanpy - INFO - Chain [1] start processing\n05:30:52 - cmdstanpy - INFO - Chain [1] done processing\n05:30:55 - cmdstanpy - INFO - Chain [1] start processing\n05:30:55 - cmdstanpy - INFO - Chain [1] done processing\n05:30:57 - cmdstanpy - INFO - Chain [1] start processing\n05:30:58 - cmdstanpy - INFO - Chain [1] done processing\n05:31:00 - cmdstanpy - INFO - Chain [1] start processing\n05:31:00 - cmdstanpy - INFO - Chain [1] done processing\n05:31:00 - cmdstanpy - ERROR - Chain [1] error: error during processing Communication error on send\nOptimization terminated abnormally. Falling back to Newton.\n05:31:00 - cmdstanpy - INFO - Chain [1] start processing\n05:31:06 - cmdstanpy - INFO - Chain [1] done processing\n05:31:09 - cmdstanpy - INFO - Chain [1] start processing\n05:31:09 - cmdstanpy - INFO - Chain [1] done processing\n05:31:11 - cmdstanpy - INFO - Chain [1] start processing\n05:31:11 - cmdstanpy - INFO - Chain [1] done processing\n05:31:11 - cmdstanpy - ERROR - Chain [1] error: error during processing Communication error on send\nOptimization terminated abnormally. Falling back to Newton.\n05:31:11 - cmdstanpy - INFO - Chain [1] start processing\n05:31:18 - cmdstanpy - INFO - Chain [1] done processing\n05:31:20 - cmdstanpy - INFO - Chain [1] start processing\n05:31:20 - cmdstanpy - INFO - Chain [1] done processing\n05:31:23 - cmdstanpy - INFO - Chain [1] start processing\n05:31:23 - cmdstanpy - INFO - Chain [1] done processing\n05:31:23 - cmdstanpy - ERROR - Chain [1] error: error during processing Communication error on send\nOptimization terminated abnormally. Falling back to Newton.\n05:31:24 - cmdstanpy - INFO - Chain [1] start processing\n05:31:34 - cmdstanpy - INFO - Chain [1] done processing\n05:31:37 - cmdstanpy - INFO - Chain [1] start processing\n05:31:37 - cmdstanpy - INFO - Chain [1] done processing\n05:31:40 - cmdstanpy - INFO - Chain [1] start processing\n05:31:40 - cmdstanpy - INFO - Chain [1] done processing\n05:31:40 - cmdstanpy - ERROR - Chain [1] error: error during processing Communication error on send\nOptimization terminated abnormally. Falling back to Newton.\n05:31:40 - cmdstanpy - INFO - Chain [1] start processing\n05:31:57 - cmdstanpy - INFO - Chain [1] done processing\n05:31:59 - cmdstanpy - INFO - Chain [1] start processing\n05:31:59 - cmdstanpy - INFO - Chain [1] done processing\n05:32:02 - cmdstanpy - INFO - Chain [1] start processing\n05:32:02 - cmdstanpy - INFO - Chain [1] done processing\n05:32:04 - cmdstanpy - INFO - Chain [1] start processing\n05:32:04 - cmdstanpy - INFO - Chain [1] done processing\n05:32:07 - cmdstanpy - INFO - Chain [1] start processing\n05:32:07 - cmdstanpy - INFO - Chain [1] done processing\n05:32:10 - cmdstanpy - INFO - Chain [1] start processing\n05:32:10 - cmdstanpy - INFO - Chain [1] done processing\n05:32:12 - cmdstanpy - INFO - Chain [1] start processing\n05:32:12 - cmdstanpy - INFO - Chain [1] done processing\n05:32:15 - cmdstanpy - INFO - Chain [1] start processing\n05:32:15 - cmdstanpy - INFO - Chain [1] done processing\n05:32:17 - cmdstanpy - INFO - Chain [1] start processing\n05:32:17 - cmdstanpy - INFO - Chain [1] done processing\n05:32:20 - cmdstanpy - INFO - Chain [1] start processing\n05:32:20 - cmdstanpy - INFO - Chain [1] done processing\n05:32:23 - cmdstanpy - INFO - Chain [1] start processing\n05:32:23 - cmdstanpy - INFO - Chain [1] done processing\n05:32:26 - cmdstanpy - INFO - Chain [1] start processing\n05:32:26 - cmdstanpy - INFO - Chain [1] done processing\n05:32:28 - cmdstanpy - INFO - Chain [1] start processing\n05:32:28 - cmdstanpy - INFO - Chain [1] done processing\n05:32:31 - cmdstanpy - INFO - Chain [1] start processing\n05:32:31 - cmdstanpy - INFO - Chain [1] done processing\n05:32:34 - cmdstanpy - INFO - Chain [1] start processing\n05:32:34 - cmdstanpy - INFO - Chain [1] done processing\n05:32:36 - cmdstanpy - INFO - Chain [1] start processing\n05:32:36 - cmdstanpy - INFO - Chain [1] done processing\n05:32:39 - cmdstanpy - INFO - Chain [1] start processing\n05:32:39 - cmdstanpy - INFO - Chain [1] done processing\n05:32:41 - cmdstanpy - INFO - Chain [1] start processing\n05:32:41 - cmdstanpy - INFO - Chain [1] done processing\n05:32:44 - cmdstanpy - INFO - Chain [1] start processing\n05:32:44 - cmdstanpy - INFO - Chain [1] done processing\n05:32:46 - cmdstanpy - INFO - Chain [1] start processing\n05:32:47 - cmdstanpy - INFO - Chain [1] done processing\n05:32:49 - cmdstanpy - INFO - Chain [1] start processing\n05:32:49 - cmdstanpy - INFO - Chain [1] done processing\n05:32:51 - cmdstanpy - INFO - Chain [1] start processing\n05:32:51 - cmdstanpy - INFO - Chain [1] done processing\n05:32:54 - cmdstanpy - INFO - Chain [1] start processing\n05:32:54 - cmdstanpy - INFO - Chain [1] done processing\n05:32:56 - cmdstanpy - INFO - Chain [1] start processing\n05:32:56 - cmdstanpy - INFO - Chain [1] done processing\n05:32:59 - cmdstanpy - INFO - Chain [1] start processing\n05:32:59 - cmdstanpy - INFO - Chain [1] done processing\n05:33:01 - cmdstanpy - INFO - Chain [1] start processing\n05:33:01 - cmdstanpy - INFO - Chain [1] done processing\n05:33:04 - cmdstanpy - INFO - Chain [1] start processing\n05:33:04 - cmdstanpy - INFO - Chain [1] done processing\n05:33:07 - cmdstanpy - INFO - Chain [1] start processing\n05:33:07 - cmdstanpy - INFO - Chain [1] done processing\n05:33:09 - cmdstanpy - INFO - Chain [1] start processing\n05:33:09 - cmdstanpy - INFO - Chain [1] done processing\n05:33:12 - cmdstanpy - INFO - Chain [1] start processing\n05:33:12 - cmdstanpy - INFO - Chain [1] done processing\n05:33:14 - cmdstanpy - INFO - Chain [1] start processing\n05:33:14 - cmdstanpy - INFO - Chain [1] done processing\n05:33:17 - cmdstanpy - INFO - Chain [1] start processing\n05:33:17 - cmdstanpy - INFO - Chain [1] done processing\n05:33:19 - cmdstanpy - INFO - Chain [1] start processing\n05:33:19 - cmdstanpy - INFO - Chain [1] done processing\n05:33:22 - cmdstanpy - INFO - Chain [1] start processing\n05:33:22 - cmdstanpy - INFO - Chain [1] done processing\n05:33:25 - cmdstanpy - INFO - Chain [1] start processing\n05:33:25 - cmdstanpy - INFO - Chain [1] done processing\n05:33:27 - cmdstanpy - INFO - Chain [1] start processing\n05:33:27 - cmdstanpy - INFO - Chain [1] done processing\n05:33:30 - cmdstanpy - INFO - Chain [1] start processing\n05:33:30 - cmdstanpy - INFO - Chain [1] done processing\n05:33:32 - cmdstanpy - INFO - Chain [1] start processing\n05:33:32 - cmdstanpy - INFO - Chain [1] done processing\n05:33:35 - cmdstanpy - INFO - Chain [1] start processing\n05:33:37 - cmdstanpy - INFO - Chain [1] done processing\n05:33:39 - cmdstanpy - INFO - Chain [1] start processing\n05:33:43 - cmdstanpy - INFO - Chain [1] done processing\n05:33:45 - cmdstanpy - INFO - Chain [1] start processing\n05:33:47 - cmdstanpy - INFO - Chain [1] done processing\n05:33:50 - cmdstanpy - INFO - Chain [1] start processing\n05:33:52 - cmdstanpy - INFO - Chain [1] done processing\n05:33:55 - cmdstanpy - INFO - Chain [1] start processing\n05:33:57 - cmdstanpy - INFO - Chain [1] done processing\n05:33:59 - cmdstanpy - INFO - Chain [1] start processing\n05:34:03 - cmdstanpy - INFO - Chain [1] done processing\n05:34:05 - cmdstanpy - INFO - Chain [1] start processing\n05:34:09 - cmdstanpy - INFO - Chain [1] done processing\n05:34:11 - cmdstanpy - INFO - Chain [1] start processing\n05:34:14 - cmdstanpy - INFO - Chain [1] done processing\n05:34:16 - cmdstanpy - INFO - Chain [1] start processing\n05:34:19 - cmdstanpy - INFO - Chain [1] done processing\n05:34:21 - cmdstanpy - INFO - Chain [1] start processing\n05:34:24 - cmdstanpy - INFO - Chain [1] done processing\n05:34:26 - cmdstanpy - INFO - Chain [1] start processing\n05:34:29 - cmdstanpy - INFO - Chain [1] done processing\n05:34:32 - cmdstanpy - INFO - Chain [1] start processing\n05:34:35 - cmdstanpy - INFO - Chain [1] done processing\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">05:23:18 - cmdstanpy - INFO - Chain [1] start processing\n05:23:20 - cmdstanpy - INFO - Chain [1] done processing\n05:23:23 - cmdstanpy - INFO - Chain [1] start processing\n05:23:23 - cmdstanpy - INFO - Chain [1] done processing\n05:23:26 - cmdstanpy - INFO - Chain [1] start processing\n05:23:26 - cmdstanpy - INFO - Chain [1] done processing\n05:23:28 - cmdstanpy - INFO - Chain [1] start processing\n05:23:28 - cmdstanpy - INFO - Chain [1] done processing\n05:23:31 - cmdstanpy - INFO - Chain [1] start processing\n05:23:32 - cmdstanpy - INFO - Chain [1] done processing\n05:23:32 - cmdstanpy - ERROR - Chain [1] error: error during processing Communication error on send\nOptimization terminated abnormally. Falling back to Newton.\n05:23:32 - cmdstanpy - INFO - Chain [1] start processing\n05:23:36 - cmdstanpy - INFO - Chain [1] done processing\n05:23:38 - cmdstanpy - INFO - Chain [1] start processing\n05:23:38 - cmdstanpy - INFO - Chain [1] done processing\n05:23:41 - cmdstanpy - INFO - Chain [1] start processing\n05:23:41 - cmdstanpy - INFO - Chain [1] done processing\n05:23:41 - cmdstanpy - ERROR - Chain [1] error: error during processing Communication error on send\nOptimization terminated abnormally. Falling back to Newton.\n05:23:41 - cmdstanpy - INFO - Chain [1] start processing\n05:23:45 - cmdstanpy - INFO - Chain [1] done processing\n05:23:47 - cmdstanpy - INFO - Chain [1] start processing\n05:23:47 - cmdstanpy - INFO - Chain [1] done processing\n05:23:50 - cmdstanpy - INFO - Chain [1] start processing\n05:23:50 - cmdstanpy - INFO - Chain [1] done processing\n05:23:53 - cmdstanpy - INFO - Chain [1] start processing\n05:23:53 - cmdstanpy - INFO - Chain [1] done processing\n05:23:56 - cmdstanpy - INFO - Chain [1] start processing\n05:23:56 - cmdstanpy - INFO - Chain [1] done processing\n05:23:58 - cmdstanpy - INFO - Chain [1] start processing\n05:23:58 - cmdstanpy - INFO - Chain [1] done processing\n05:24:01 - cmdstanpy - INFO - Chain [1] start processing\n05:24:01 - cmdstanpy - INFO - Chain [1] done processing\n05:24:03 - cmdstanpy - INFO - Chain [1] start processing\n05:24:03 - cmdstanpy - INFO - Chain [1] done processing\n05:24:06 - cmdstanpy - INFO - Chain [1] start processing\n05:24:06 - cmdstanpy - INFO - Chain [1] done processing\n05:24:09 - cmdstanpy - INFO - Chain [1] start processing\n05:24:09 - cmdstanpy - INFO - Chain [1] done processing\n05:24:11 - cmdstanpy - INFO - Chain [1] start processing\n05:24:11 - cmdstanpy - INFO - Chain [1] done processing\n05:24:14 - cmdstanpy - INFO - Chain [1] start processing\n05:24:14 - cmdstanpy - INFO - Chain [1] done processing\n05:24:16 - cmdstanpy - INFO - Chain [1] start processing\n05:24:16 - cmdstanpy - INFO - Chain [1] done processing\n05:24:19 - cmdstanpy - INFO - Chain [1] start processing\n05:24:19 - cmdstanpy - INFO - Chain [1] done processing\n05:24:21 - cmdstanpy - INFO - Chain [1] start processing\n05:24:21 - cmdstanpy - INFO - Chain [1] done processing\n05:24:24 - cmdstanpy - INFO - Chain [1] start processing\n05:24:24 - cmdstanpy - INFO - Chain [1] done processing\n05:24:26 - cmdstanpy - INFO - Chain [1] start processing\n05:24:26 - cmdstanpy - INFO - Chain [1] done processing\n05:24:29 - cmdstanpy - INFO - Chain [1] start processing\n05:24:29 - cmdstanpy - INFO - Chain [1] done processing\n05:24:31 - cmdstanpy - INFO - Chain [1] start processing\n05:24:31 - cmdstanpy - INFO - Chain [1] done processing\n05:24:34 - cmdstanpy - INFO - Chain [1] start processing\n05:24:34 - cmdstanpy - INFO - Chain [1] done processing\n05:24:37 - cmdstanpy - INFO - Chain [1] start processing\n05:24:37 - cmdstanpy - INFO - Chain [1] done processing\n05:24:39 - cmdstanpy - INFO - Chain [1] start processing\n05:24:39 - cmdstanpy - INFO - Chain [1] done processing\n05:24:42 - cmdstanpy - INFO - Chain [1] start processing\n05:24:42 - cmdstanpy - INFO - Chain [1] done processing\n05:24:45 - cmdstanpy - INFO - Chain [1] start processing\n05:24:45 - cmdstanpy - INFO - Chain [1] done processing\n05:24:47 - cmdstanpy - INFO - Chain [1] start processing\n05:24:47 - cmdstanpy - INFO - Chain [1] done processing\n05:24:50 - cmdstanpy - INFO - Chain [1] start processing\n05:24:50 - cmdstanpy - INFO - Chain [1] done processing\n05:24:53 - cmdstanpy - INFO - Chain [1] start processing\n05:24:53 - cmdstanpy - INFO - Chain [1] done processing\n05:24:55 - cmdstanpy - INFO - Chain [1] start processing\n05:24:55 - cmdstanpy - INFO - Chain [1] done processing\n05:24:58 - cmdstanpy - INFO - Chain [1] start processing\n05:24:58 - cmdstanpy - INFO - Chain [1] done processing\n05:25:00 - cmdstanpy - INFO - Chain [1] start processing\n05:25:01 - cmdstanpy - INFO - Chain [1] done processing\n05:25:03 - cmdstanpy - INFO - Chain [1] start processing\n05:25:03 - cmdstanpy - INFO - Chain [1] done processing\n05:25:06 - cmdstanpy - INFO - Chain [1] start processing\n05:25:06 - cmdstanpy - INFO - Chain [1] done processing\n05:25:09 - cmdstanpy - INFO - Chain [1] start processing\n05:25:09 - cmdstanpy - INFO - Chain [1] done processing\n05:25:12 - cmdstanpy - INFO - Chain [1] start processing\n05:25:12 - cmdstanpy - INFO - Chain [1] done processing\n05:25:14 - cmdstanpy - INFO - Chain [1] start processing\n05:25:14 - cmdstanpy - INFO - Chain [1] done processing\n05:25:17 - cmdstanpy - INFO - Chain [1] start processing\n05:25:17 - cmdstanpy - INFO - Chain [1] done processing\n05:25:19 - cmdstanpy - INFO - Chain [1] start processing\n05:25:19 - cmdstanpy - INFO - Chain [1] done processing\n05:25:22 - cmdstanpy - INFO - Chain [1] start processing\n05:25:22 - cmdstanpy - INFO - Chain [1] done processing\n05:25:25 - cmdstanpy - INFO - Chain [1] start processing\n05:25:25 - cmdstanpy - INFO - Chain [1] done processing\n05:25:28 - cmdstanpy - INFO - Chain [1] start processing\n05:25:28 - cmdstanpy - INFO - Chain [1] done processing\n05:25:30 - cmdstanpy - INFO - Chain [1] start processing\n05:25:30 - cmdstanpy - INFO - Chain [1] done processing\n05:25:33 - cmdstanpy - INFO - Chain [1] start processing\n05:25:33 - cmdstanpy - INFO - Chain [1] done processing\n05:25:35 - cmdstanpy - INFO - Chain [1] start processing\n05:25:36 - cmdstanpy - INFO - Chain [1] done processing\n05:25:38 - cmdstanpy - INFO - Chain [1] start processing\n05:25:38 - cmdstanpy - INFO - Chain [1] done processing\n05:25:41 - cmdstanpy - INFO - Chain [1] start processing\n05:25:41 - cmdstanpy - INFO - Chain [1] done processing\n05:25:43 - cmdstanpy - INFO - Chain [1] start processing\n05:25:43 - cmdstanpy - INFO - Chain [1] done processing\n05:25:46 - cmdstanpy - INFO - Chain [1] start processing\n05:25:46 - cmdstanpy - INFO - Chain [1] done processing\n05:25:48 - cmdstanpy - INFO - Chain [1] start processing\n05:25:48 - cmdstanpy - INFO - Chain [1] done processing\n05:25:51 - cmdstanpy - INFO - Chain [1] start processing\n05:25:51 - cmdstanpy - INFO - Chain [1] done processing\n05:25:53 - cmdstanpy - INFO - Chain [1] start processing\n05:25:54 - cmdstanpy - INFO - Chain [1] done processing\n05:25:56 - cmdstanpy - INFO - Chain [1] start processing\n05:25:56 - cmdstanpy - INFO - Chain [1] done processing\n05:25:59 - cmdstanpy - INFO - Chain [1] start processing\n05:25:59 - cmdstanpy - INFO - Chain [1] done processing\n05:26:01 - cmdstanpy - INFO - Chain [1] start processing\n05:26:01 - cmdstanpy - INFO - Chain [1] done processing\n05:26:04 - cmdstanpy - INFO - Chain [1] start processing\n05:26:04 - cmdstanpy - INFO - Chain [1] done processing\n05:26:06 - cmdstanpy - INFO - Chain [1] start processing\n05:26:06 - cmdstanpy - INFO - Chain [1] done processing\n05:26:09 - cmdstanpy - INFO - Chain [1] start processing\n05:26:09 - cmdstanpy - INFO - Chain [1] done processing\n05:26:12 - cmdstanpy - INFO - Chain [1] start processing\n05:26:12 - cmdstanpy - INFO - Chain [1] done processing\n05:26:14 - cmdstanpy - INFO - Chain [1] start processing\n05:26:14 - cmdstanpy - INFO - Chain [1] done processing\n05:26:17 - cmdstanpy - INFO - Chain [1] start processing\n05:26:17 - cmdstanpy - INFO - Chain [1] done processing\n05:26:19 - cmdstanpy - INFO - Chain [1] start processing\n05:26:19 - cmdstanpy - INFO - Chain [1] done processing\n05:26:22 - cmdstanpy - INFO - Chain [1] start processing\n05:26:22 - cmdstanpy - INFO - Chain [1] done processing\n05:26:25 - cmdstanpy - INFO - Chain [1] start processing\n05:26:25 - cmdstanpy - INFO - Chain [1] done processing\n05:26:27 - cmdstanpy - INFO - Chain [1] start processing\n05:26:27 - cmdstanpy - INFO - Chain [1] done processing\n05:26:30 - cmdstanpy - INFO - Chain [1] start processing\n05:26:30 - cmdstanpy - INFO - Chain [1] done processing\n05:26:32 - cmdstanpy - INFO - Chain [1] start processing\n05:26:32 - cmdstanpy - INFO - Chain [1] done processing\n05:26:35 - cmdstanpy - INFO - Chain [1] start processing\n05:26:35 - cmdstanpy - INFO - Chain [1] done processing\n05:26:37 - cmdstanpy - INFO - Chain [1] start processing\n05:26:37 - cmdstanpy - INFO - Chain [1] done processing\n05:26:40 - cmdstanpy - INFO - Chain [1] start processing\n05:26:40 - cmdstanpy - INFO - Chain [1] done processing\n05:26:43 - cmdstanpy - INFO - Chain [1] start processing\n05:26:43 - cmdstanpy - INFO - Chain [1] done processing\n05:26:45 - cmdstanpy - INFO - Chain [1] start processing\n05:26:45 - cmdstanpy - INFO - Chain [1] done processing\n05:26:48 - cmdstanpy - INFO - Chain [1] start processing\n05:26:48 - cmdstanpy - INFO - Chain [1] done processing\n05:26:50 - cmdstanpy - INFO - Chain [1] start processing\n05:26:50 - cmdstanpy - INFO - Chain [1] done processing\n05:26:53 - cmdstanpy - INFO - Chain [1] start processing\n05:26:53 - cmdstanpy - INFO - Chain [1] done processing\n05:26:56 - cmdstanpy - INFO - Chain [1] start processing\n05:26:56 - cmdstanpy - INFO - Chain [1] done processing\n05:26:58 - cmdstanpy - INFO - Chain [1] start processing\n05:26:58 - cmdstanpy - INFO - Chain [1] done processing\n05:27:01 - cmdstanpy - INFO - Chain [1] start processing\n05:27:01 - cmdstanpy - INFO - Chain [1] done processing\n05:27:03 - cmdstanpy - INFO - Chain [1] start processing\n05:27:03 - cmdstanpy - INFO - Chain [1] done processing\n05:27:06 - cmdstanpy - INFO - Chain [1] start processing\n05:27:06 - cmdstanpy - INFO - Chain [1] done processing\n05:27:09 - cmdstanpy - INFO - Chain [1] start processing\n05:27:09 - cmdstanpy - INFO - Chain [1] done processing\n05:27:11 - cmdstanpy - INFO - Chain [1] start processing\n05:27:11 - cmdstanpy - INFO - Chain [1] done processing\n05:27:14 - cmdstanpy - INFO - Chain [1] start processing\n05:27:14 - cmdstanpy - INFO - Chain [1] done processing\n05:27:16 - cmdstanpy - INFO - Chain [1] start processing\n05:27:16 - cmdstanpy - INFO - Chain [1] done processing\n05:27:19 - cmdstanpy - INFO - Chain [1] start processing\n05:27:19 - cmdstanpy - INFO - Chain [1] done processing\n05:27:21 - cmdstanpy - INFO - Chain [1] start processing\n05:27:21 - cmdstanpy - INFO - Chain [1] done processing\n05:27:24 - cmdstanpy - INFO - Chain [1] start processing\n05:27:24 - cmdstanpy - INFO - Chain [1] done processing\n05:27:26 - cmdstanpy - INFO - Chain [1] start processing\n05:27:27 - cmdstanpy - INFO - Chain [1] done processing\n05:27:29 - cmdstanpy - INFO - Chain [1] start processing\n05:27:29 - cmdstanpy - INFO - Chain [1] done processing\n05:27:32 - cmdstanpy - INFO - Chain [1] start processing\n05:27:32 - cmdstanpy - INFO - Chain [1] done processing\n05:27:34 - cmdstanpy - INFO - Chain [1] start processing\n05:27:34 - cmdstanpy - INFO - Chain [1] done processing\n05:27:37 - cmdstanpy - INFO - Chain [1] start processing\n05:27:37 - cmdstanpy - INFO - Chain [1] done processing\n05:27:40 - cmdstanpy - INFO - Chain [1] start processing\n05:27:40 - cmdstanpy - INFO - Chain [1] done processing\n05:27:43 - cmdstanpy - INFO - Chain [1] start processing\n05:27:43 - cmdstanpy - INFO - Chain [1] done processing\n05:27:45 - cmdstanpy - INFO - Chain [1] start processing\n05:27:45 - cmdstanpy - INFO - Chain [1] done processing\n05:27:48 - cmdstanpy - INFO - Chain [1] start processing\n05:27:48 - cmdstanpy - INFO - Chain [1] done processing\n05:27:50 - cmdstanpy - INFO - Chain [1] start processing\n05:27:50 - cmdstanpy - INFO - Chain [1] done processing\n05:27:53 - cmdstanpy - INFO - Chain [1] start processing\n05:27:53 - cmdstanpy - INFO - Chain [1] done processing\n05:27:56 - cmdstanpy - INFO - Chain [1] start processing\n05:27:56 - cmdstanpy - INFO - Chain [1] done processing\n05:27:58 - cmdstanpy - INFO - Chain [1] start processing\n05:27:58 - cmdstanpy - INFO - Chain [1] done processing\n05:28:01 - cmdstanpy - INFO - Chain [1] start processing\n05:28:01 - cmdstanpy - INFO - Chain [1] done processing\n05:28:03 - cmdstanpy - INFO - Chain [1] start processing\n05:28:03 - cmdstanpy - INFO - Chain [1] done processing\n05:28:06 - cmdstanpy - INFO - Chain [1] start processing\n05:28:06 - cmdstanpy - INFO - Chain [1] done processing\n05:28:08 - cmdstanpy - INFO - Chain [1] start processing\n05:28:08 - cmdstanpy - INFO - Chain [1] done processing\n05:28:11 - cmdstanpy - INFO - Chain [1] start processing\n05:28:12 - cmdstanpy - INFO - Chain [1] done processing\n05:28:14 - cmdstanpy - INFO - Chain [1] start processing\n05:28:14 - cmdstanpy - INFO - Chain [1] done processing\n05:28:17 - cmdstanpy - INFO - Chain [1] start processing\n05:28:17 - cmdstanpy - INFO - Chain [1] done processing\n05:28:19 - cmdstanpy - INFO - Chain [1] start processing\n05:28:19 - cmdstanpy - INFO - Chain [1] done processing\n05:28:22 - cmdstanpy - INFO - Chain [1] start processing\n05:28:22 - cmdstanpy - INFO - Chain [1] done processing\n05:28:24 - cmdstanpy - INFO - Chain [1] start processing\n05:28:24 - cmdstanpy - INFO - Chain [1] done processing\n05:28:27 - cmdstanpy - INFO - Chain [1] start processing\n05:28:27 - cmdstanpy - INFO - Chain [1] done processing\n05:28:29 - cmdstanpy - INFO - Chain [1] start processing\n05:28:29 - cmdstanpy - INFO - Chain [1] done processing\n05:28:32 - cmdstanpy - INFO - Chain [1] start processing\n05:28:32 - cmdstanpy - INFO - Chain [1] done processing\n05:28:34 - cmdstanpy - INFO - Chain [1] start processing\n05:28:34 - cmdstanpy - INFO - Chain [1] done processing\n05:28:37 - cmdstanpy - INFO - Chain [1] start processing\n05:28:37 - cmdstanpy - INFO - Chain [1] done processing\n05:28:39 - cmdstanpy - INFO - Chain [1] start processing\n05:28:39 - cmdstanpy - INFO - Chain [1] done processing\n05:28:42 - cmdstanpy - INFO - Chain [1] start processing\n05:28:42 - cmdstanpy - INFO - Chain [1] done processing\n05:28:44 - cmdstanpy - INFO - Chain [1] start processing\n05:28:45 - cmdstanpy - INFO - Chain [1] done processing\n05:28:47 - cmdstanpy - INFO - Chain [1] start processing\n05:28:47 - cmdstanpy - INFO - Chain [1] done processing\n05:28:50 - cmdstanpy - INFO - Chain [1] start processing\n05:28:50 - cmdstanpy - INFO - Chain [1] done processing\n05:28:52 - cmdstanpy - INFO - Chain [1] start processing\n05:28:52 - cmdstanpy - INFO - Chain [1] done processing\n05:28:55 - cmdstanpy - INFO - Chain [1] start processing\n05:28:55 - cmdstanpy - INFO - Chain [1] done processing\n05:28:57 - cmdstanpy - INFO - Chain [1] start processing\n05:28:57 - cmdstanpy - INFO - Chain [1] done processing\n05:29:00 - cmdstanpy - INFO - Chain [1] start processing\n05:29:00 - cmdstanpy - INFO - Chain [1] done processing\n05:29:03 - cmdstanpy - INFO - Chain [1] start processing\n05:29:03 - cmdstanpy - INFO - Chain [1] done processing\n05:29:05 - cmdstanpy - INFO - Chain [1] start processing\n05:29:05 - cmdstanpy - INFO - Chain [1] done processing\n05:29:08 - cmdstanpy - INFO - Chain [1] start processing\n05:29:08 - cmdstanpy - INFO - Chain [1] done processing\n05:29:10 - cmdstanpy - INFO - Chain [1] start processing\n05:29:10 - cmdstanpy - INFO - Chain [1] done processing\n05:29:13 - cmdstanpy - INFO - Chain [1] start processing\n05:29:13 - cmdstanpy - INFO - Chain [1] done processing\n05:29:15 - cmdstanpy - INFO - Chain [1] start processing\n05:29:16 - cmdstanpy - INFO - Chain [1] done processing\n05:29:18 - cmdstanpy - INFO - Chain [1] start processing\n05:29:18 - cmdstanpy - INFO - Chain [1] done processing\n05:29:21 - cmdstanpy - INFO - Chain [1] start processing\n05:29:21 - cmdstanpy - INFO - Chain [1] done processing\n05:29:24 - cmdstanpy - INFO - Chain [1] start processing\n05:29:24 - cmdstanpy - INFO - Chain [1] done processing\n05:29:26 - cmdstanpy - INFO - Chain [1] start processing\n05:29:26 - cmdstanpy - INFO - Chain [1] done processing\n05:29:29 - cmdstanpy - INFO - Chain [1] start processing\n05:29:29 - cmdstanpy - INFO - Chain [1] done processing\n05:29:31 - cmdstanpy - INFO - Chain [1] start processing\n05:29:31 - cmdstanpy - INFO - Chain [1] done processing\n05:29:34 - cmdstanpy - INFO - Chain [1] start processing\n05:29:34 - cmdstanpy - INFO - Chain [1] done processing\n05:29:36 - cmdstanpy - INFO - Chain [1] start processing\n05:29:36 - cmdstanpy - INFO - Chain [1] done processing\n05:29:39 - cmdstanpy - INFO - Chain [1] start processing\n05:29:39 - cmdstanpy - INFO - Chain [1] done processing\n05:29:41 - cmdstanpy - INFO - Chain [1] start processing\n05:29:41 - cmdstanpy - INFO - Chain [1] done processing\n05:29:44 - cmdstanpy - INFO - Chain [1] start processing\n05:29:44 - cmdstanpy - INFO - Chain [1] done processing\n05:29:47 - cmdstanpy - INFO - Chain [1] start processing\n05:29:47 - cmdstanpy - INFO - Chain [1] done processing\n05:29:49 - cmdstanpy - INFO - Chain [1] start processing\n05:29:49 - cmdstanpy - INFO - Chain [1] done processing\n05:29:52 - cmdstanpy - INFO - Chain [1] start processing\n05:29:52 - cmdstanpy - INFO - Chain [1] done processing\n05:29:54 - cmdstanpy - INFO - Chain [1] start processing\n05:29:54 - cmdstanpy - INFO - Chain [1] done processing\n05:29:57 - cmdstanpy - INFO - Chain [1] start processing\n05:29:57 - cmdstanpy - INFO - Chain [1] done processing\n05:30:00 - cmdstanpy - INFO - Chain [1] start processing\n05:30:00 - cmdstanpy - INFO - Chain [1] done processing\n05:30:03 - cmdstanpy - INFO - Chain [1] start processing\n05:30:03 - cmdstanpy - INFO - Chain [1] done processing\n05:30:06 - cmdstanpy - INFO - Chain [1] start processing\n05:30:06 - cmdstanpy - INFO - Chain [1] done processing\n05:30:08 - cmdstanpy - INFO - Chain [1] start processing\n05:30:09 - cmdstanpy - INFO - Chain [1] done processing\n05:30:14 - cmdstanpy - INFO - Chain [1] start processing\n05:30:14 - cmdstanpy - INFO - Chain [1] done processing\n05:30:16 - cmdstanpy - INFO - Chain [1] start processing\n05:30:16 - cmdstanpy - INFO - Chain [1] done processing\n05:30:19 - cmdstanpy - INFO - Chain [1] start processing\n05:30:19 - cmdstanpy - INFO - Chain [1] done processing\n05:30:21 - cmdstanpy - INFO - Chain [1] start processing\n05:30:21 - cmdstanpy - INFO - Chain [1] done processing\n05:30:24 - cmdstanpy - INFO - Chain [1] start processing\n05:30:24 - cmdstanpy - INFO - Chain [1] done processing\n05:30:26 - cmdstanpy - INFO - Chain [1] start processing\n05:30:26 - cmdstanpy - INFO - Chain [1] done processing\n05:30:29 - cmdstanpy - INFO - Chain [1] start processing\n05:30:29 - cmdstanpy - INFO - Chain [1] done processing\n05:30:31 - cmdstanpy - INFO - Chain [1] start processing\n05:30:31 - cmdstanpy - INFO - Chain [1] done processing\n05:30:34 - cmdstanpy - INFO - Chain [1] start processing\n05:30:34 - cmdstanpy - INFO - Chain [1] done processing\n05:30:37 - cmdstanpy - INFO - Chain [1] start processing\n05:30:37 - cmdstanpy - INFO - Chain [1] done processing\n05:30:39 - cmdstanpy - INFO - Chain [1] start processing\n05:30:39 - cmdstanpy - INFO - Chain [1] done processing\n05:30:42 - cmdstanpy - INFO - Chain [1] start processing\n05:30:42 - cmdstanpy - INFO - Chain [1] done processing\n05:30:45 - cmdstanpy - INFO - Chain [1] start processing\n05:30:45 - cmdstanpy - INFO - Chain [1] done processing\n05:30:47 - cmdstanpy - INFO - Chain [1] start processing\n05:30:47 - cmdstanpy - INFO - Chain [1] done processing\n05:30:50 - cmdstanpy - INFO - Chain [1] start processing\n05:30:50 - cmdstanpy - INFO - Chain [1] done processing\n05:30:52 - cmdstanpy - INFO - Chain [1] start processing\n05:30:52 - cmdstanpy - INFO - Chain [1] done processing\n05:30:55 - cmdstanpy - INFO - Chain [1] start processing\n05:30:55 - cmdstanpy - INFO - Chain [1] done processing\n05:30:57 - cmdstanpy - INFO - Chain [1] start processing\n05:30:58 - cmdstanpy - INFO - Chain [1] done processing\n05:31:00 - cmdstanpy - INFO - Chain [1] start processing\n05:31:00 - cmdstanpy - INFO - Chain [1] done processing\n05:31:00 - cmdstanpy - ERROR - Chain [1] error: error during processing Communication error on send\nOptimization terminated abnormally. Falling back to Newton.\n05:31:00 - cmdstanpy - INFO - Chain [1] start processing\n05:31:06 - cmdstanpy - INFO - Chain [1] done processing\n05:31:09 - cmdstanpy - INFO - Chain [1] start processing\n05:31:09 - cmdstanpy - INFO - Chain [1] done processing\n05:31:11 - cmdstanpy - INFO - Chain [1] start processing\n05:31:11 - cmdstanpy - INFO - Chain [1] done processing\n05:31:11 - cmdstanpy - ERROR - Chain [1] error: error during processing Communication error on send\nOptimization terminated abnormally. Falling back to Newton.\n05:31:11 - cmdstanpy - INFO - Chain [1] start processing\n05:31:18 - cmdstanpy - INFO - Chain [1] done processing\n05:31:20 - cmdstanpy - INFO - Chain [1] start processing\n05:31:20 - cmdstanpy - INFO - Chain [1] done processing\n05:31:23 - cmdstanpy - INFO - Chain [1] start processing\n05:31:23 - cmdstanpy - INFO - Chain [1] done processing\n05:31:23 - cmdstanpy - ERROR - Chain [1] error: error during processing Communication error on send\nOptimization terminated abnormally. Falling back to Newton.\n05:31:24 - cmdstanpy - INFO - Chain [1] start processing\n05:31:34 - cmdstanpy - INFO - Chain [1] done processing\n05:31:37 - cmdstanpy - INFO - Chain [1] start processing\n05:31:37 - cmdstanpy - INFO - Chain [1] done processing\n05:31:40 - cmdstanpy - INFO - Chain [1] start processing\n05:31:40 - cmdstanpy - INFO - Chain [1] done processing\n05:31:40 - cmdstanpy - ERROR - Chain [1] error: error during processing Communication error on send\nOptimization terminated abnormally. Falling back to Newton.\n05:31:40 - cmdstanpy - INFO - Chain [1] start processing\n05:31:57 - cmdstanpy - INFO - Chain [1] done processing\n05:31:59 - cmdstanpy - INFO - Chain [1] start processing\n05:31:59 - cmdstanpy - INFO - Chain [1] done processing\n05:32:02 - cmdstanpy - INFO - Chain [1] start processing\n05:32:02 - cmdstanpy - INFO - Chain [1] done processing\n05:32:04 - cmdstanpy - INFO - Chain [1] start processing\n05:32:04 - cmdstanpy - INFO - Chain [1] done processing\n05:32:07 - cmdstanpy - INFO - Chain [1] start processing\n05:32:07 - cmdstanpy - INFO - Chain [1] done processing\n05:32:10 - cmdstanpy - INFO - Chain [1] start processing\n05:32:10 - cmdstanpy - INFO - Chain [1] done processing\n05:32:12 - cmdstanpy - INFO - Chain [1] start processing\n05:32:12 - cmdstanpy - INFO - Chain [1] done processing\n05:32:15 - cmdstanpy - INFO - Chain [1] start processing\n05:32:15 - cmdstanpy - INFO - Chain [1] done processing\n05:32:17 - cmdstanpy - INFO - Chain [1] start processing\n05:32:17 - cmdstanpy - INFO - Chain [1] done processing\n05:32:20 - cmdstanpy - INFO - Chain [1] start processing\n05:32:20 - cmdstanpy - INFO - Chain [1] done processing\n05:32:23 - cmdstanpy - INFO - Chain [1] start processing\n05:32:23 - cmdstanpy - INFO - Chain [1] done processing\n05:32:26 - cmdstanpy - INFO - Chain [1] start processing\n05:32:26 - cmdstanpy - INFO - Chain [1] done processing\n05:32:28 - cmdstanpy - INFO - Chain [1] start processing\n05:32:28 - cmdstanpy - INFO - Chain [1] done processing\n05:32:31 - cmdstanpy - INFO - Chain [1] start processing\n05:32:31 - cmdstanpy - INFO - Chain [1] done processing\n05:32:34 - cmdstanpy - INFO - Chain [1] start processing\n05:32:34 - cmdstanpy - INFO - Chain [1] done processing\n05:32:36 - cmdstanpy - INFO - Chain [1] start processing\n05:32:36 - cmdstanpy - INFO - Chain [1] done processing\n05:32:39 - cmdstanpy - INFO - Chain [1] start processing\n05:32:39 - cmdstanpy - INFO - Chain [1] done processing\n05:32:41 - cmdstanpy - INFO - Chain [1] start processing\n05:32:41 - cmdstanpy - INFO - Chain [1] done processing\n05:32:44 - cmdstanpy - INFO - Chain [1] start processing\n05:32:44 - cmdstanpy - INFO - Chain [1] done processing\n05:32:46 - cmdstanpy - INFO - Chain [1] start processing\n05:32:47 - cmdstanpy - INFO - Chain [1] done processing\n05:32:49 - cmdstanpy - INFO - Chain [1] start processing\n05:32:49 - cmdstanpy - INFO - Chain [1] done processing\n05:32:51 - cmdstanpy - INFO - Chain [1] start processing\n05:32:51 - cmdstanpy - INFO - Chain [1] done processing\n05:32:54 - cmdstanpy - INFO - Chain [1] start processing\n05:32:54 - cmdstanpy - INFO - Chain [1] done processing\n05:32:56 - cmdstanpy - INFO - Chain [1] start processing\n05:32:56 - cmdstanpy - INFO - Chain [1] done processing\n05:32:59 - cmdstanpy - INFO - Chain [1] start processing\n05:32:59 - cmdstanpy - INFO - Chain [1] done processing\n05:33:01 - cmdstanpy - INFO - Chain [1] start processing\n05:33:01 - cmdstanpy - INFO - Chain [1] done processing\n05:33:04 - cmdstanpy - INFO - Chain [1] start processing\n05:33:04 - cmdstanpy - INFO - Chain [1] done processing\n05:33:07 - cmdstanpy - INFO - Chain [1] start processing\n05:33:07 - cmdstanpy - INFO - Chain [1] done processing\n05:33:09 - cmdstanpy - INFO - Chain [1] start processing\n05:33:09 - cmdstanpy - INFO - Chain [1] done processing\n05:33:12 - cmdstanpy - INFO - Chain [1] start processing\n05:33:12 - cmdstanpy - INFO - Chain [1] done processing\n05:33:14 - cmdstanpy - INFO - Chain [1] start processing\n05:33:14 - cmdstanpy - INFO - Chain [1] done processing\n05:33:17 - cmdstanpy - INFO - Chain [1] start processing\n05:33:17 - cmdstanpy - INFO - Chain [1] done processing\n05:33:19 - cmdstanpy - INFO - Chain [1] start processing\n05:33:19 - cmdstanpy - INFO - Chain [1] done processing\n05:33:22 - cmdstanpy - INFO - Chain [1] start processing\n05:33:22 - cmdstanpy - INFO - Chain [1] done processing\n05:33:25 - cmdstanpy - INFO - Chain [1] start processing\n05:33:25 - cmdstanpy - INFO - Chain [1] done processing\n05:33:27 - cmdstanpy - INFO - Chain [1] start processing\n05:33:27 - cmdstanpy - INFO - Chain [1] done processing\n05:33:30 - cmdstanpy - INFO - Chain [1] start processing\n05:33:30 - cmdstanpy - INFO - Chain [1] done processing\n05:33:32 - cmdstanpy - INFO - Chain [1] start processing\n05:33:32 - cmdstanpy - INFO - Chain [1] done processing\n05:33:35 - cmdstanpy - INFO - Chain [1] start processing\n05:33:37 - cmdstanpy - INFO - Chain [1] done processing\n05:33:39 - cmdstanpy - INFO - Chain [1] start processing\n05:33:43 - cmdstanpy - INFO - Chain [1] done processing\n05:33:45 - cmdstanpy - INFO - Chain [1] start processing\n05:33:47 - cmdstanpy - INFO - Chain [1] done processing\n05:33:50 - cmdstanpy - INFO - Chain [1] start processing\n05:33:52 - cmdstanpy - INFO - Chain [1] done processing\n05:33:55 - cmdstanpy - INFO - Chain [1] start processing\n05:33:57 - cmdstanpy - INFO - Chain [1] done processing\n05:33:59 - cmdstanpy - INFO - Chain [1] start processing\n05:34:03 - cmdstanpy - INFO - Chain [1] done processing\n05:34:05 - cmdstanpy - INFO - Chain [1] start processing\n05:34:09 - cmdstanpy - INFO - Chain [1] done processing\n05:34:11 - cmdstanpy - INFO - Chain [1] start processing\n05:34:14 - cmdstanpy - INFO - Chain [1] done processing\n05:34:16 - cmdstanpy - INFO - Chain [1] start processing\n05:34:19 - cmdstanpy - INFO - Chain [1] done processing\n05:34:21 - cmdstanpy - INFO - Chain [1] start processing\n05:34:24 - cmdstanpy - INFO - Chain [1] done processing\n05:34:26 - cmdstanpy - INFO - Chain [1] start processing\n05:34:29 - cmdstanpy - INFO - Chain [1] done processing\n05:34:32 - cmdstanpy - INFO - Chain [1] start processing\n05:34:35 - cmdstanpy - INFO - Chain [1] done processing\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Choosing the best hyperparameters"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5d3920a5-24a2-4c93-85a5-cd50bcbc184d","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Reading the latest file based on timestamp\nall_files = [file for file in os.listdir(algo_path)]\nbacktesting_files = [file for file in all_files if \"Backtesting_results_window_level (\" in file]\nbacktesting_files = [file.replace(\".csv\",\"\") for file in backtesting_files]\nversion_dates = [datetime.strptime(x.split('(')[1].replace(')',''), '%Y-%m-%d-%H-%M-%S') for x in backtesting_files]\nmax_date = max(version_dates)\nmax_date = max_date.strftime('%Y-%m-%d-%H-%M-%S')\nreq_file_name = [x for x in backtesting_files if max_date in x]\nbacktesting_results_file_path = os.path.join(algo_path,req_file_name[0] + \".csv\")\n# print(backtesting_results_file_path)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d0fe8642-6703-409f-aab8-76afb0a446ad","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Reading the results of backtesting\ndf = pd.read_csv(backtesting_results_file_path)\ndf = df[df['status'] == 'success']\n# display(df)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"24056638-6110-4b31-bc67-1cec1967ee1a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Roll up the metrics at Modeling granularity x Hyperparameter space x window level\nwindow_level = modeling_granularity_conf + list(hyperparameters_conf.keys()) + [\"window\"]\n# print(window_level)\nwindow_level_results = df.groupby(window_level)[[\"mape\",\"wmape\",\"bias\",\"tracking_signal\",\"mae\",\"rmse\"]].min().reset_index()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b983b722-2113-4af3-ab73-93f33d945985","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Roll up the metrics at Modeling granularity x Hyperparameter space level\nhyperparam_level = modeling_granularity_conf + list(hyperparameters_conf.keys())\nhyperparam_level_results = window_level_results.groupby(hyperparam_level)[[\"mape\",\"wmape\",\"bias\",\"tracking_signal\",\"mae\",\"rmse\"]].mean().reset_index()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5932262a-cfe8-4ea6-a95a-520803c376d2","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["hyperparam_level_results.to_csv(algo_path + \"/Backtesting_results_hyperparameter_level (\" + datetime.today().strftime('%Y-%m-%d-%H-%M-%S')+\").csv\", index = False)\nlogger.info(\"Exported backtesting results\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f9c26b88-0942-48fa-86c9-0a43cfabcbd2","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Pandas UDF for getting best hyperparameters & MLFlow tracking"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"38b81392-8332-4222-9b6e-54e4d8c76eda","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["hyperparam_level_results['algorithm'] = 'Prophet'\nhyperparam_level_results['result_type'] = 'backtesting'"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2e49037f-e116-4bb2-91b6-de7d68c41801","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def get_best_hyperparameters(final_hyperparam_df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Function for getting the best hyperparameters results for each modeling granularity along with MLFlow tracking using the broadcasted information from the config file\n\n    Parameters\n    ----------\n    final_hyperparam_df : pd.DataFrame\n        Dataframe containing the results of Backtesting \n\n    Returns\n    -------\n    pd.DataFrame\n        Dataset with best hyperparameter set for each modeling granularity\n    \"\"\"\n    try:\n        results_pd = {}\n\n        # Get the modeling granularity\n        broadcast_gran = broadcast_granularity.value\n        # Get the experiment id\n        tracking_value = broadcast_tracking.value.copy()\n\n        # To adhere to defined schema\n        for x in broadcast_gran:\n            results_pd[x] = final_hyperparam_df[x].astype(str).iloc[0]\n\n        hp_config = broadcast_hyper_parameters.value\n        granularity = broadcast_granularity.value\n        \n        if tracking_value[\"tracking_needed\"] == True:\n            if tracking_value[\"type\"] != \"Managed\":\n                if tracking_value[\"tracking_uri\"] is not None:\n                    mlflow.set_tracking_uri(\"file:\" + tracking_value[\"tracking_uri\"])\n                    experiment_id = mlflow.set_experiment(tracking_value[\"mlflow_experiment_id\"])\n                    tracking_value['mlflow_experiment_id'] = experiment_id.experiment_id\n\n            # Add MLFlow code here\n            with mlflow.start_run(experiment_id=tracking_value[\"mlflow_experiment_id\"]):\n                for x in [\"algorithm\",'result_type'] + broadcast_gran:\n                    mlflow.log_param(x, final_hyperparam_df[x].iloc[0])\n                for row in range(0, len(final_hyperparam_df)):\n                    with mlflow.start_run(experiment_id=tracking_value[\"mlflow_experiment_id\"], nested=True):\n                        for x in hp_config:\n                            mlflow.log_param(x, final_hyperparam_df[x].iloc[row])\n                        for x in [\"mape\",\"wmape\",\"bias\",\"tracking_signal\",\"mae\",\"rmse\"]:\n                            mlflow.log_metric(x, final_hyperparam_df[x].iloc[row])\n\n        metric = broadcast_metric.value\n\n        # Sort using the metric of interest\n        if metric in [\"wmape\", \"mape\", \"mad\", \"mae\", \"rmse\"]:\n            final_hyperparam_df = final_hyperparam_df.sort_values(\n                metric, ascending=True\n            )\n        elif metric in [\"tracking_signal\",\"bias\"]:\n            final_hyperparam_df.sort_values(metric, ascending=True,key=abs, inplace=True)\n        else:\n            final_hyperparam_df.sort_values(metric, ascending=True, inplace=True)\n\n        # Adding the best hyperparameter and related metrics\n        for x in hp_config:\n            results_pd[x] = final_hyperparam_df[x].iloc[0]\n\n        for x in [\"mape\", \"wmape\", \"bias\", \"tracking_signal\", \"mae\", \"rmse\"]:\n            results_pd[x] = final_hyperparam_df[x].iloc[0]\n\n        results_pd[\"status\"] = \"success\"\n        return pd.DataFrame.from_dict([results_pd])\n\n    except Exception as e:\n        results_pd = pd.DataFrame(\n            columns=[[\"mape\", \"wmape\", \"bias\", \"tracking_signal\", \"mae\", \"rmse\"]+ list(broadcast_hyper_parameters.value.keys())+ [\"status\"]+ broadcast_granularity.value],\\\n            index=range(1))\n        results_pd[broadcast_granularity.value] = final_hyperparam_df[broadcast_granularity.value].head(1).reset_index(drop=True)\n        for x in broadcast_granularity.value:\n            results_pd[x] = results_pd[x].astype(str)\n        results_pd[\"status\"] = str(e)\n        return results_pd"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d076cc54-931c-4977-801e-ee2eb97f8489","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["hyperparam_level_results['gran_tempp'] = hyperparam_level_results[modeling_granularity_conf].astype(str).sum(axis=1)\nunique_pdts = hyperparam_level_results['gran_tempp'].unique()\nbest_hyperparam_results = pd.DataFrame()\nfor pdt in unique_pdts:\n    best_hyperparam_results = pd.concat([best_hyperparam_results,get_best_hyperparameters(hyperparam_level_results[hyperparam_level_results['gran_tempp']==pdt])])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8fc3b197-7f7f-445e-947e-e7fa14c458b7","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Writing the best hyperparameter results"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2088e5a8-f151-4247-92c0-91affb414828","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["best_hyperparam_results.to_csv(algo_path + \"/Best_hyperparameters (\" + datetime.today().strftime('%Y-%m-%d-%H-%M-%S')+\").csv\", index = False)\nlogger.info(\"Exported best hyperparameter results\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3d9f3c4f-c922-499e-9aee-db30f6e49b33","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Exporting config file\nconfig_file_name = \"config_for_exp_id_\"+str(broadcast_tracking.value['mlflow_experiment_id']) + \" (\" +datetime.today().strftime('%Y-%m-%d-%H-%M-%S-%f')[:-3]+\").yml\"\nconfig_path1 = os.path.join(config_path,config_file_name)\nwith open(config_path1, 'w') as file:\n    yaml.dump(temp_config, file, default_flow_style=False,sort_keys=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c2be5580-027f-4bd1-bf1c-6b5be781613f","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Move from tmp directory to req. location in datalake\nimport platform\nplat_sys = platform.system()\n\nif(plat_sys!='Windows'):\n    log_file = log_file.replace(' (', '\\ \\(').replace(')','\\)')\n    os.system('mv /tmp/{0} {1}'.format(log_file,logs_path))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3c73d8ad-fd51-493a-b886-c9d8c1f79c78","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.8.10","nbconvert_exporter":"python","file_extension":".py"},"application/vnd.databricks.v1+notebook":{"notebookName":"1.1 - Hyperparameter tuning","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":98246570296262}},"nbformat":4,"nbformat_minor":0}