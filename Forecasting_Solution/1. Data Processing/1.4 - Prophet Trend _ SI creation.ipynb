{"cells":[{"cell_type":"markdown","source":["### Objective\nThe objective of the notebook is to calculate the trend and seasonality components using prophet at the level provided in the config(data_processing > feature_engineering > prophet_based > higher_level_si_trend_creation)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4515c5b8-083e-4cc6-8cdb-6b3310774fd5","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["import yaml\nimport inspect\nimport glob\nimport numpy as np\nimport pandas as pd\nfrom prophet import Prophet\nfrom prophet.make_holidays import make_holidays_df\nfrom distutils.command.config import config\nfrom tqdm.auto import tqdm\nfrom datetime import timedelta\nfrom datetime import datetime\nfrom sklearn.metrics import mean_absolute_error,mean_squared_error\nimport os\nimport logging\nimport dotsi"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"b002b38d-3ebb-4d31-ae5b-5ee7a9296372","inputWidgets":{},"title":"Loading relevant packages"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Getting the default settings of hyperparameters\ndef get_default_args(func) -> dict:\n    \"\"\"Function to get the default values of the hyperparameters for the given algorithm\n\n    Parameters\n    ----------\n    func : constructor of the respective algorithm\n        The name of the algorithm (Eg: Prophet,SARIMAX)\n\n    Returns\n    -------\n    dict\n        returns a dictionary of hyperparameters and the corresponding default values for the given algorithm\n    \"\"\"\n    \n    signature = inspect.signature(func)\n    return {\n        k: v.default if v.default is not inspect.Parameter.empty else None\n        for k, v in signature.parameters.items()\n        if k != 'self'\n    }"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a0a23b71-0875-4577-a441-820044250207","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Default values for the hyperparameters in Prophet\ndefault_hpps = get_default_args(Prophet)\n# default_hpps"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2114c05b-877c-4f2a-a3b8-b0dc4e6bf11e","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Broadcast helper functions\nThese functions helps to persist the data in all the workers so that we can leverage them in UDF while distributed processing"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5f9ed870-0800-4ffa-9915-379a7602ba92","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["def broadcast_holidays(\n    config_holidays: dict,\n    year_list: list =[2018, 2019, 2020, 2021, 2022],\n    country_name: str =\"US\",\n    holiday_lower_window: int =7,\n    holiday_upper_window: int =7,\n) -> pd.DataFrame:\n    \"\"\"Function to return the dataframe of holidays for the given time period using Prophet's make_holidays_df()\n\n    Parameters\n    ----------\n    config_holidays : dict\n        the additional list of holidays and its respective dates provided by the user in config file\n    year_list : list, optional\n        the list of years for which we need the holidays , by default [2018, 2019, 2020, 2021, 2022]\n    country_name : str, optional\n        Name of the country based on which holidays can be decided, by default \"US\"\n    holiday_lower_window : int, optional\n        lower limit of the window, by default 7\n    holiday_upper_window : int, optional\n        upper limit of the window, by default 7\n\n    Returns\n    -------\n    pd.DataFrame\n        Returns a dataframe of holidays for the given time period\n    \"\"\"\n    holidays = make_holidays_df(year_list, country_name)\n    # Add window\n    holidays['lower_window'] = -holiday_lower_window\n    holidays['upper_window'] = holiday_upper_window\n    \n    # Adding additional holidays\n    if config_holidays is not None:\n        for ad_hol in config_holidays.keys():\n            temp_df = pd.DataFrame({'holiday':ad_hol,\n                                    'ds': pd.to_datetime(config_holidays[ad_hol]['ds']),\n                                    'lower_window': -holiday_lower_window,\n                                    'upper_window': holiday_upper_window})\n            holidays = pd.concat([holidays,temp_df])\n    \n    # Dropping duplicates if exists any\n    holidays = holidays.drop_duplicates().reset_index(drop = True)\n    return holidays"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a1a9eb20-e108-4e72-ae5c-b1839b7e6cd5","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Processing Config file\nDependent variable, date variable, modeling granularity & other related modeling details are provided in the form of a config file.Each TS Algorithm and the related hyperparameter values to be tried should given in the config.yml file"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"477f6174-472e-461f-8ade-5f01b15d5fbd","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%run ../0_Config.ipynb"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"94c35c06-1e39-456e-b4c4-662338ab33ac","inputWidgets":{},"title":"Reading the model configuration file"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Create the algo directory for storing the results\noutput_directory = app_config['output_dir_path']\nroot_dir = \"Data_Processing\"\ncategory = \"higher_level_trend_si\"\nalgo_path = os.path.join(output_directory,root_dir,category)\nif not os.path.exists(algo_path):\n    os.makedirs(algo_path)\n    print(algo_path)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"28c88109-9a40-4416-8b9c-c62a548a1705","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Broadcasting the required variables\nVariables suffixed with \"_conf\" are taken from the config file"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"48b33369-0dad-4b07-a6d4-acb4938bc689","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# hyperparameters_conf = dict(app_config[\"Algorithms\"][\"Prophet\"][\"Hyperparameters\"])\nhyperparameters_conf = default_hpps\n# print(hyperparameters_conf)\n\ngranularity_conf = app_config[\"data_processing\"]['feature_engineering']['prophet_based'][\"higher_level_si_trend_creation\"][\"granularity\"]\nmodeling_granularity_conf = app_config[\"modeling_granularity\"]\n# print(granularity_conf)\n\n# Rename Start date and DV config\ndv_config = app_config[\"data_processing\"]['feature_engineering']['prophet_based'][\"higher_level_si_trend_creation\"][\"sales_variable\"]\nds_config = app_config[\"date_var\"]\n\n# Broadcasting\nif app_config[\"data_processing\"][\"feature_engineering\"]['prophet_based'][\"Holidays\"][\"include_holidays\"] == True:\n    aa = app_config[\"data_processing\"][\"feature_engineering\"]['prophet_based'][\"Holidays\"]\n    holidays_broadcast = broadcast_holidays(aa['additional_holidays'],aa['years'],aa['country'],aa['holiday_lower_window'],aa['holiday_upper_window'])\n    holidays_broadcast = dotsi.Dict({\"value\":holidays_broadcast})\nelse:\n    holidays_broadcast = dotsi.Dict({\"value\":None})\n    \nbroadcast_granularity = dotsi.Dict({\"value\":granularity_conf})\nbroadcast_hyper_parameters = dotsi.Dict({\"value\":hyperparameters_conf})\nbroadcast_future_weeks = dotsi.Dict({\"value\":app_config[\"data_processing\"][\"feature_engineering\"]['prophet_based'][\"future_n_datapoints\"]})"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c7cf1130-97c1-4db5-9ea9-2fef3e547887","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Pandas UDF for creating trend\nThe UDF gets executed in multiple worker nodes to parallelize the process. All the broadcasted variables are accessed within the UDF as and when required"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9356e913-fb1d-4b08-86f5-11b05414d1c4","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["def get_forecast_UDF(df_data: pd.DataFrame)-> pd.DataFrame:\n    \"\"\"Function to perform final model building using the train data and score on the test data utilizing the broadcasted details from the config file\n\n    Parameters\n    ----------\n    df_data : pd.DataFrame\n        The dataset containing values for all the required variables\n\n    Returns\n    -------\n    pd.DataFrame\n      Returns a dataframe with the granularity,date,independent variables contributions if any and performance metrics for the training and thetesting       set\n    \"\"\"\n    try:\n        df_data = df_data.sort_values(by=['ds'],ascending=True)\n\n        # broadcast_granularity\n        broadcast_gran = broadcast_granularity.value\n\n        # Updating the default arguments with the parameters provided in the config\n        hp_config = broadcast_hyper_parameters.value\n        def_args = get_default_args(Prophet)\n        for x in list(broadcast_hyper_parameters.value):\n            def_args[x] = hp_config[x]\n            \n        if holidays_broadcast.value is not None:\n            def_args[\"holidays\"] = holidays_broadcast.value\n            \n        def_args['yearly_seasonality'] = True\n        def_args['weekly_seasonality'] = True\n        def_args['daily_seasonality'] = True\n\n        # Calling the Prophet constructor with the hyperparameters of interest  \n        m = Prophet(**def_args)\n        m.fit(df_data)\n        forecast_pd = m.predict(df_data)\n        \n        seasonal_cols = ['yearly','weekly','daily']\n        seasonal_cols_zero = list(set(seasonal_cols) - set(forecast_pd.columns))\n        forecast_pd[seasonal_cols_zero] = 0\n        \n        results_pd = forecast_pd[['ds', 'yhat', 'yhat_upper','yhat_lower','trend']+seasonal_cols]\n        results_pd = pd.merge(results_pd, df_data[['y','ds']+broadcast_gran], how = \"left\",on = \"ds\")\n        results_pd['future_weeks'] = 0\n        \n        # Infering frequency\n        history_dates = pd.to_datetime(pd.Series(results_pd['ds'].unique(), name='ds')).sort_values()\n        freq = pd.infer_freq(history_dates.tail(3))\n        # returns None if inference failed\n        if freq is None:\n            raise Exception('Unable to infer `freq`')\n\n        # making future week\n        future_weeks = broadcast_future_weeks.value\n        if(future_weeks>0):\n            future = m.make_future_dataframe(periods=future_weeks, freq=freq, include_history=False)\n            forecast = m.predict(future)\n            forecast[seasonal_cols_zero] = 0\n            forecast1 = forecast[['ds', 'yhat', 'yhat_upper','yhat_lower','trend']+seasonal_cols]\n            forecast1['y'] = 0\n            forecast1['future_weeks'] = 1\n            fin_df = pd.concat([results_pd,forecast1],ignore_index=True)\n        else:\n            fin_df = results_pd.copy()\n            \n        fin_df[broadcast_gran] = fin_df[broadcast_gran].fillna(method='ffill')\n        # To adhere to defined schema\n        for x in broadcast_gran:   \n            fin_df[x] = fin_df[x].astype(str)\n            \n        fin_df['status'] = 'success'\n        return fin_df\n    \n    except Exception as e:\n        results_pd = pd.DataFrame(columns = [['ds', 'y', 'yhat','yhat_upper','yhat_lower','trend','yearly','weekly','daily','future_weeks','status'] \\\n                                             + broadcast_granularity.value],index = range(1))\n        results_pd[broadcast_granularity.value] = df_data[broadcast_granularity.value].head(1).reset_index(drop = True)\n        for x in broadcast_granularity.value:\n              results_pd[x] = results_pd[x].astype(str)\n        results_pd['status'] = str(e)\n        return results_pd"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"73134801-892a-4ebf-99e2-597fd496e261","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def data_loading(path):\n    if os.path.isdir(path):  \n        all_files = os.listdir(path)\n        all_files_ext = []\n        for file_name in all_files:\n            all_files_ext.append(os.path.splitext(file_name)[1])\n        df = pd.DataFrame()\n        \n        if(\".csv\" in all_files_ext):\n            for file_name in all_files:\n                if('.csv' in file_name):\n                    df = pd.concat([df,pd.read_csv(path + \"/\" + file_name)], ignore_index = True)\n            return df\n        elif(\".parquet\" in all_files_ext):\n            for file_name in all_files:\n                if('.parquet' in file_name):\n                    df = pd.concat([df,pd.read_parquet(path + \"/\" + file_name, engine='pyarrow')], ignore_index = True)\n            return df    \n        else:\n            assert False, \"Only .csv or .parquet file types are supported\"\n        \n    elif os.path.isfile(path):  \n        file_type = os.path.splitext(path)[1]\n        if(\".csv\" == file_type):\n            df = pd.read_csv(path)\n            return df\n        elif(\".parquet\" == file_type):\n            df = pd.read_parquet(path, engine='pyarrow')\n            return df\n        else:\n            assert False, \"Only .csv or .parquet file types are supported\"\n    else:  \n        assert False, 'Path specified is not correct'"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"04a3ff2a-33ec-4683-b399-02cf46d927e4","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Load data"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f4359d1d-2c02-4825-9fc3-8888eb42d01e","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["if(app_config[\"data_processing\"][\"outlier_treatment_needed\"] == True):\n    # Reading the latest input file based on timestamp\n    all_files = [file for file in os.listdir(app_config['output_dir_path']+\"/Data_Processing/Outlier_treatment\")]\n    outlier_op_files = [file for file in all_files if \"Outlier_treatment_results (\" in file]\n    outlier_op_files = [file.replace(\".csv\",\"\") for file in outlier_op_files]\n    version_dates = [datetime.strptime(x.split('(')[1].replace(')',''), '%Y-%m-%d-%H-%M-%S') for x in outlier_op_files]\n    max_date = max(version_dates)\n    max_date = max_date.strftime('%Y-%m-%d-%H-%M-%S')\n    req_file_name = [x for x in outlier_op_files if max_date in x]\n    outlier_op_file_path = os.path.join(app_config['output_dir_path']+\"/Data_Processing/Outlier_treatment\",req_file_name[0] + \".csv\")\n    # print(outlier_op_file_path)\n\n    # Reading the data\n    df = pd.read_csv(outlier_op_file_path)\nelse:\n    df = data_loading(app_config[\"input_file_path\"])\n    \n# print(df.shape)\ndf.rename(columns = {ds_config:\"ds\", dv_config:\"y\"}, inplace = True)\ndf['ds'] = pd.to_datetime(df['ds'],format = app_config[\"date_format_pandas\"])\ndf[modeling_granularity_conf] = df[modeling_granularity_conf].astype(str)\n    \n\nstart_date= app_config[\"data_processing\"]['feature_engineering']['prophet_based'][\"higher_level_si_trend_creation\"][\"start_date\"]\nend_date= app_config[\"data_processing\"]['feature_engineering']['prophet_based'][\"higher_level_si_trend_creation\"][\"end_date\"]\n\nif((len(start_date)>1) & (len(end_date)>1)):\n    start_date = datetime.strptime(start_date, app_config[\"date_format_pandas\"])\n    end_date = datetime.strptime(end_date, app_config[\"date_format_pandas\"])\n    print(df.shape)\n    df = df[(df['ds']>=start_date) & (df['ds']<=end_date)]\nelse:\n    start_date = df['ds'].min()\n    end_date = df['ds'].max()\n\n# filtering the products based on start and end date\ngran = list(set(granularity_conf+modeling_granularity_conf))\ntemp = df.groupby(gran).agg(min_ds = ('ds','min'), max_ds = ('ds','max')).reset_index()  \ntemp2 = temp[(temp[\"min_ds\"]==start_date) & (temp[\"max_ds\"]==end_date)]\n\ntot_pdts = temp.shape[0]\ntot_sum = df['y'].sum()\ndf = df.merge(temp2,on=gran,how='right')\nrem_sum = df['y'].sum()\n\nprint(\"Out of \"+ str(tot_pdts) + \" combinations, \"+str(tot_pdts-temp2.shape[0]) + \" combinations are getting dropped bcz of the date filters\")\nprint(\"Dropped products conntributed around \" + str(np.round((tot_sum-rem_sum)/tot_sum*100,1)) + \"%\")\n\n# Aggregating the data at granularity level\ndf1 = df.groupby(granularity_conf + ['ds']).agg(y = ('y','sum')).reset_index()\n\ndf1['gran_tempp'] = df1[granularity_conf].astype(str).sum(axis=1)\nunique_pdts = df1['gran_tempp'].unique()\nresults_s = pd.DataFrame()\nfor pdt in unique_pdts:\n\tresults_s = pd.concat([results_s,get_forecast_UDF(df1[df1['gran_tempp']==pdt])])\n# display(results_s)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"059292d9-604a-4b1a-9018-15bfe630c158","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out of 7 combinations, 1 combinations are getting dropped bcz of the date filters\nDropped products conntributed around 5.9%\n13:53:40 - cmdstanpy - INFO - Chain [1] start processing\n13:53:40 - cmdstanpy - INFO - Chain [1] done processing\n&lt;command-3460216454770688&gt;:60: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  forecast1[&#39;y&#39;] = 0\n&lt;command-3460216454770688&gt;:61: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  forecast1[&#39;future_weeks&#39;] = 1\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out of 7 combinations, 1 combinations are getting dropped bcz of the date filters\nDropped products conntributed around 5.9%\n13:53:40 - cmdstanpy - INFO - Chain [1] start processing\n13:53:40 - cmdstanpy - INFO - Chain [1] done processing\n&lt;command-3460216454770688&gt;:60: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  forecast1[&#39;y&#39;] = 0\n&lt;command-3460216454770688&gt;:61: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  forecast1[&#39;future_weeks&#39;] = 1\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Exporting higher level trend results"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f5efb2ae-3ecd-49f5-970f-38254768382c","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["results_s.to_csv(algo_path+\"/higher_level_trend_si_results (\"+datetime.today().strftime('%Y-%m-%d-%H-%M-%S')+\").csv\", index = False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7e8f99e9-1666-4328-8a74-612dd09a4611","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"1.4 - Prophet Trend & SI creation","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":98246570295948}},"nbformat":4,"nbformat_minor":0}